"""
G2MILPè®­ç»ƒæ¨¡å—
G2MILP Training Module

å®ç°G2MILPçš„è®­ç»ƒé€»è¾‘ï¼ŒåŒ…æ‹¬ï¼š
1. åŸºäºå•ä¸ª"æœ‰åå·®"å®ä¾‹çš„è‡ªæˆ‘å­¦ä¹ è®­ç»ƒ
2. æŸå¤±å‡½æ•°è®¡ç®—å’Œä¼˜åŒ–
3. è®­ç»ƒè¿›åº¦ç›‘æ§å’Œæ—¥å¿—è®°å½•
4. æ¨¡å‹ä¿å­˜å’Œæ¢å¤
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR
from torch.cuda.amp import autocast, GradScaler
from torch_geometric.data import HeteroData
import numpy as np
import logging
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict
import json
from pathlib import Path
from datetime import datetime
import time
from tqdm import tqdm
import matplotlib.pyplot as plt
import threading
from concurrent.futures import ThreadPoolExecutor, Future

from .generator import G2MILPGenerator, GeneratorConfig
from .evaluation import G2MILPEvaluator, EvaluationConfig
from .inference import G2MILPInference, InferenceConfig
from .early_stopping import EarlyStoppingMonitor, EarlyStoppingConfig, create_early_stopping_monitor

logger = logging.getLogger(__name__)


@dataclass
class TrainingConfig:
    """è®­ç»ƒé…ç½®"""
    # åŸºç¡€è®­ç»ƒå‚æ•°ï¼ˆå¤§å¹…æå‡è®­ç»ƒå¼ºåº¦ï¼‰
    num_epochs: int = 5000           # å¤§å¹…å¢åŠ è®­ç»ƒè½®æ•°
    batch_size: int = 1              # å¯¹äºå•å®ä¾‹è®­ç»ƒï¼Œbatch_size=1
    learning_rate: float = 1e-4      # é™ä½åˆå§‹å­¦ä¹ ç‡ï¼Œå¢å¼ºç¨³å®šæ€§
    weight_decay: float = 1e-3       # æé«˜æƒé‡è¡°å‡
    
    # å­¦ä¹ ç‡è°ƒåº¦å¢å¼º
    use_lr_scheduler: bool = True
    scheduler_type: str = "cosine_with_warmup"  # plateau, cosine, cosine_with_warmup, cosine_restart
    lr_patience: int = 50
    lr_factor: float = 0.5
    lr_min: float = 1e-6
    lr_scheduler_factor: float = 0.8  # å…¼å®¹åˆ«å
    lr_scheduler_patience: int = 20    # å…¼å®¹åˆ«åï¼Œå¢åŠ patience
    
    # å­¦ä¹ ç‡é¢„çƒ­å’Œé‡å¯
    warmup_epochs: int = 50           # é¢„çƒ­epochæ•°
    warmup_start_lr: float = 1e-6     # é¢„çƒ­èµ·å§‹å­¦ä¹ ç‡
    cosine_restart_period: int = 500   # Cosineé‡å¯å‘¨æœŸ
    restart_mult: float = 2.0         # é‡å¯å‘¨æœŸå€æ•°
    
    # æ¢¯åº¦è£å‰ª
    grad_clip_norm: float = 1.0
    
    # è®­ç»ƒç­–ç•¥ï¼ˆå¢å¼ºç‰ˆï¼‰
    iterations_per_epoch: int = 200  # æ¯ä¸ªepochå†…çš„è¿­ä»£æ¬¡æ•°ï¼ˆç¿»å€ï¼‰
    validation_frequency: int = 50   # éªŒè¯é¢‘ç‡ï¼ˆepochï¼‰
    save_frequency: int = 500        # æ¨¡å‹ä¿å­˜é¢‘ç‡ï¼ˆepochï¼‰
    
    # å¾®æ‰¹æ¬¡ç´¯ç§¯ï¼ˆæé«˜GPUåˆ©ç”¨ç‡ï¼‰
    micro_batch_size: int = 4        # å¾®æ‰¹æ¬¡å¤§å°ï¼ˆç´¯ç§¯4æ¬¡å‰å‘ä¼ æ’­ï¼‰
    gradient_accumulation_steps: int = 4  # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
    
    # æ—©åœå¢å¼ºï¼ˆæ›´å®½æ¾çš„ç­–ç•¥ï¼‰
    use_early_stopping: bool = True
    early_stopping_patience: int = 500   # è¶…å¤§patienceï¼Œé€‚åˆé•¿æœŸè®­ç»ƒ
    early_stopping_min_delta: float = 1e-6  # æ›´æ•æ„Ÿçš„min_delta
    min_delta: float = 1e-6              # å…¼å®¹åˆ«å
    
    # é«˜çº§Early Stoppingé…ç½®
    early_stopping_strategy: str = "combined"  # simple, multi_metric, adaptive, trend_analysis, combined
    early_stopping_monitor_metrics: List[str] = None  # é¢å¤–ç›‘æ§æŒ‡æ ‡
    early_stopping_quality_threshold: float = 0.7     # è´¨é‡é˜ˆå€¼
    early_stopping_adaptive_patience: bool = True     # è‡ªé€‚åº”patience
    early_stopping_trend_analysis: bool = True        # è¶‹åŠ¿åˆ†æ
    early_stopping_verbose: bool = True               # è¯¦ç»†æ—¥å¿—
    
    # æŸå¤±æƒé‡è°ƒåº¦ï¼ˆè¯¾ç¨‹å­¦ä¹ å¢å¼ºï¼‰
    kl_annealing: bool = True
    kl_annealing_epochs: int = 800       # å¤§å¹…å»¶é•¿é€€ç«æœŸ
    kl_start_weight: float = 0.0
    kl_end_weight: float = 1.0
    
    # æ–°å¢ï¼šæ•°æ®å¢å¼ºå‚æ•°
    use_data_augmentation: bool = True
    feature_noise_std: float = 0.05      # ç‰¹å¾å™ªå£°æ ‡å‡†å·®ï¼ˆÂ±5%ï¼‰
    edge_perturbation_prob: float = 0.1  # è¾¹æ‰°åŠ¨æ¦‚ç‡
    
    # æ–°å¢ï¼šä¼˜åŒ–å™¨å¢å¼º
    optimizer_type: str = "adamw"        # ä½¿ç”¨AdamWä¼˜åŒ–å™¨
    use_gradient_accumulation: bool = False  # æ¢¯åº¦ç´¯ç§¯ï¼ˆå•å®ä¾‹ä¸éœ€è¦ï¼‰
    
    # RTX 3060 Tiä¸“é¡¹ä¼˜åŒ–
    use_mixed_precision: bool = True     # å¯ç”¨AMPæ··åˆç²¾åº¦è®­ç»ƒï¼ˆRTX 30ç³»åˆ—æ”¯æŒï¼‰
    amp_loss_scale: str = "dynamic"      # AMPæŸå¤±ç¼©æ”¾ç­–ç•¥ dynamic/static/value
    use_compile: bool = False            # PyTorch 2.0ç¼–è¯‘ä¼˜åŒ–ï¼ˆå¯é€‰ï¼‰
    
    # ç¨€ç–æ€§æ­£åˆ™åŒ–æ–°å¢
    use_sparsity_regularization: bool = True
    sparsity_weight: float = 0.01     # ç¨€ç–æ€§æŸå¤±æƒé‡
    target_sparsity: float = 0.1      # ç›®æ ‡ç¨€ç–åº¦ï¼ˆè¾¹æ•°æ¯”ä¾‹ï¼‰
    
    # æ•°å€¼ç¨³å®šæ€§
    loss_nan_threshold: float = 1000.0  # NaN/Infæ›¿æ¢é˜ˆå€¼
    gradient_nan_check: bool = True     # æ¢¯åº¦NaNæ£€æŸ¥
    
    # æ—¥å¿—å’Œä¿å­˜
    log_interval: int = 10  # æ—¥å¿—è®°å½•é—´éš”ï¼ˆiterationï¼‰
    save_dir: str = "output/demo4_g2milp/training"
    experiment_name: str = f"g2milp_training_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    # è´¨é‡è¯„ä¼°é…ç½®ï¼ˆæ–°å¢ï¼‰
    enable_quality_evaluation: bool = True       # å¯ç”¨è´¨é‡è¯„ä¼°
    quality_evaluation_frequency: int = 50       # è´¨é‡è¯„ä¼°é¢‘ç‡ï¼ˆepochï¼‰
    quality_samples_per_eval: int = 3           # æ¯æ¬¡è¯„ä¼°ç”Ÿæˆçš„æ ·æœ¬æ•°
    enable_detailed_quality_logging: bool = True # å¯ç”¨è¯¦ç»†è´¨é‡æ—¥å¿—
    
    # è®¾å¤‡
    device: str = "cuda" if torch.cuda.is_available() else "cpu"


class G2MILPTrainer:
    """
    G2MILPè®­ç»ƒå™¨
    
    ä¸“é—¨é’ˆå¯¹å•ä¸ª"æœ‰åå·®"å®ä¾‹çš„è‡ªæˆ‘å­¦ä¹ è®­ç»ƒè¿‡ç¨‹
    """
    
    def __init__(self, 
                 model: G2MILPGenerator,
                 config: TrainingConfig = None,
                 evaluator = None):
        self.model = model
        self.config = config or TrainingConfig()
        self.evaluator = evaluator  # åœ¨çº¿è´¨é‡è¯„ä¼°å™¨
        
        # è®¾ç½®è®¾å¤‡
        self.device = torch.device(self.config.device)
        self.model = self.model.to(self.device)
        
        # ä¼˜åŒ–å™¨ï¼ˆæ”¯æŒå¤šç§ç±»å‹ï¼‰
        self.optimizer = self._create_optimizer()
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = self._create_scheduler()
        
        # AMPæ··åˆç²¾åº¦æ”¯æŒï¼ˆRTX 3060 Tiä¼˜åŒ–ï¼‰
        self.use_amp = getattr(self.config, 'use_mixed_precision', True) and torch.cuda.is_available()
        if self.use_amp:
            self.scaler = GradScaler()
            logger.info("å·²å¯ç”¨AMPæ··åˆç²¾åº¦è®­ç»ƒ (RTX 30ç³»åˆ—ä¼˜åŒ–)")
        else:
            self.scaler = None
            
        # PyTorch 2.0ç¼–è¯‘ä¼˜åŒ–
        if getattr(self.config, 'use_compile', False) and hasattr(torch, 'compile'):
            try:
                self.model = torch.compile(self.model)
                logger.info("å·²å¯ç”¨PyTorch 2.0ç¼–è¯‘ä¼˜åŒ–")
            except Exception as e:
                logger.warning(f"ç¼–è¯‘ä¼˜åŒ–å¤±è´¥: {e}")
        
        # è®­ç»ƒçŠ¶æ€
        self.current_epoch = 0
        self.current_iteration = 0
        self.best_loss = float('inf')
        self.training_history = {
            'train_loss': [],
            'val_loss': [],
            'learning_rate': [],
            'kl_weight': [],
            # è¯¦ç»†æŸå¤±åˆ†è§£
            'train_reconstruction': [],
            'train_kl_raw': [],
            'train_bias': [],
            'train_degree': [],
            'train_logits': [],
            'train_weights': [],
            'train_sparsity': [],
            'val_reconstruction': [],
            'val_kl_raw': [],
            # æ¢¯åº¦å’Œå‚æ•°ç»Ÿè®¡
            'grad_norm': [],
            'grad_max': [],
            'param_norm': [],
            'nan_grads': [],
            'inf_grads': [],
            # åœ¨çº¿è´¨é‡è¯„ä¼°
            'validity_score': [],
            'diversity_score': [],
            'similarity_score': [],
            'stability_score': [],
            'quality_overall': [],
            # æ–°å¢ï¼šè´¨é‡è¯„ä¼°å†å²è®°å½•
            'generation_quality': [],
            'validity_scores': [],
            'diversity_scores': [],
            'similarity_scores': []
        }
        
        # é«˜çº§Early Stoppingç›‘æ§å™¨
        if self.config.use_early_stopping:
            early_stopping_config = EarlyStoppingConfig(
                strategy=getattr(self.config, 'early_stopping_strategy', 'combined'),
                patience=self.config.early_stopping_patience,
                min_delta=self.config.early_stopping_min_delta,
                monitor_metric='val_loss',
                additional_metrics=getattr(self.config, 'early_stopping_monitor_metrics', 
                                         ['train_loss', 'kl_weight', 'grad_norm', 'generation_quality']),
                adaptive_patience=getattr(self.config, 'early_stopping_adaptive_patience', True),
                trend_window=20,
                enable_quality_monitoring=getattr(self.config, 'enable_quality_evaluation', True),
                quality_threshold=getattr(self.config, 'early_stopping_quality_threshold', 0.7),
                verbose=getattr(self.config, 'early_stopping_verbose', True),
                save_best_model=True,
                restore_best_weights=True
            )
            self.early_stopping_monitor = EarlyStoppingMonitor(early_stopping_config)
            logger.info(f"âœ… é«˜çº§Early Stoppingç›‘æ§å™¨å·²å¯ç”¨ (ç­–ç•¥: {early_stopping_config.strategy.value})")
        else:
            self.early_stopping_monitor = None
        
        # ä¼ ç»Ÿæ—©åœï¼ˆå…¼å®¹æ€§ä¿ç•™ï¼‰
        self.early_stopping_counter = 0
        self.should_stop = False
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        self.save_dir = Path(self.config.save_dir) / self.config.experiment_name
        self.save_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–è´¨é‡è¯„ä¼°å™¨ï¼ˆæ–°å¢ï¼‰
        if getattr(self.config, 'enable_quality_evaluation', True):
            eval_config = EvaluationConfig(
                enable_graph_similarity=True,
                enable_milp_similarity=True,
                enable_diversity_analysis=True,
                enable_training_monitoring=True,
                diversity_sample_size=getattr(self.config, 'quality_samples_per_eval', 3),
                generate_visualizations=False,  # è®­ç»ƒæ—¶ä¸ç”Ÿæˆå¯è§†åŒ–ï¼Œé¿å…è¿‡å¤šæ–‡ä»¶
                save_detailed_results=False,     # è®­ç»ƒæ—¶ä¸ä¿å­˜è¯¦ç»†ç»“æœ
                output_dir=str(self.save_dir / "quality_evaluation")
            )
            self.quality_evaluator = G2MILPEvaluator(eval_config)
            
            # åˆå§‹åŒ–æ¨ç†å™¨ç”¨äºè´¨é‡è¯„ä¼°
            inference_config = InferenceConfig(
                num_test_instances=getattr(self.config, 'quality_samples_per_eval', 3),
                eta=0.1,
                sample_from_prior=True,
                constraint_selection_strategy="random"
            )
            self.quality_inferencer = None  # å»¶è¿Ÿåˆå§‹åŒ–ï¼Œå› ä¸ºéœ€è¦æ¨¡å‹
        else:
            self.quality_evaluator = None
            self.quality_inferencer = None
        
        logger.info(f"G2MILPè®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"è®¾å¤‡: {self.device}")
        logger.info(f"ä¼˜åŒ–å™¨: {self.config.optimizer_type}")
        logger.info(f"ä¿å­˜ç›®å½•: {self.save_dir}")
        logger.info(f"è´¨é‡è¯„ä¼°: {'å¯ç”¨' if self.quality_evaluator else 'ç¦ç”¨'}")
    
    def _create_optimizer(self):
        """åˆ›å»ºä¼˜åŒ–å™¨"""
        optimizer_type = getattr(self.config, 'optimizer_type', 'adam').lower()
        
        if optimizer_type == 'adamw':
            return optim.AdamW(
                self.model.parameters(),
                lr=self.config.learning_rate,
                weight_decay=self.config.weight_decay,
                betas=(0.9, 0.999),
                eps=1e-8
            )
        elif optimizer_type == 'adam':
            return optim.Adam(
                self.model.parameters(),
                lr=self.config.learning_rate,
                weight_decay=self.config.weight_decay,
                betas=(0.9, 0.999),
                eps=1e-8
            )
        elif optimizer_type == 'sgd':
            return optim.SGD(
                self.model.parameters(),
                lr=self.config.learning_rate,
                weight_decay=self.config.weight_decay,
                momentum=0.9,
                nesterov=True
            )
        else:
            logger.warning(f"æœªçŸ¥çš„ä¼˜åŒ–å™¨ç±»å‹: {optimizer_type}, ä½¿ç”¨é»˜è®¤AdamW")
            return optim.AdamW(
                self.model.parameters(),
                lr=self.config.learning_rate,
                weight_decay=self.config.weight_decay
            )
    
    def _create_scheduler(self):
        """åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨"""
        if not self.config.use_lr_scheduler:
            return None
        
        scheduler_type = self.config.scheduler_type
        
        if scheduler_type == "plateau":
            # æ”¯æŒæ–°çš„é…ç½®å‚æ•°åç§°
            factor = getattr(self.config, 'lr_scheduler_factor', self.config.lr_factor)
            patience = getattr(self.config, 'lr_scheduler_patience', self.config.lr_patience)
            
            return ReduceLROnPlateau(
                self.optimizer,
                mode='min',
                factor=factor,
                patience=patience,
                min_lr=self.config.lr_min
            )
        elif scheduler_type == "cosine":
            return CosineAnnealingLR(
                self.optimizer,
                T_max=self.config.num_epochs,
                eta_min=self.config.lr_min
            )
        elif scheduler_type == "cosine_with_warmup":
            # è‡ªå®šä¹‰çš„Cosine with Warmupè°ƒåº¦å™¨
            return self._create_cosine_warmup_scheduler()
        elif scheduler_type == "cosine_restart":
            # Cosine Annealing with Warm Restarts
            from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts
            return CosineAnnealingWarmRestarts(
                self.optimizer,
                T_0=self.config.cosine_restart_period,
                T_mult=int(self.config.restart_mult),
                eta_min=self.config.lr_min
            )
        else:
            logger.warning(f"æœªçŸ¥çš„è°ƒåº¦å™¨ç±»å‹: {scheduler_type}, ä½¿ç”¨é»˜è®¤plateau")
            return ReduceLROnPlateau(
                self.optimizer,
                mode='min',
                factor=0.5,
                patience=50,
                min_lr=self.config.lr_min
            )
    
    def _create_cosine_warmup_scheduler(self):
        """åˆ›å»ºå¸¦é¢„çƒ­çš„Cosineè°ƒåº¦å™¨ï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
        from torch.optim.lr_scheduler import LambdaLR
        import math
        
        def lr_lambda(current_step: int) -> float:
            if current_step < self.config.warmup_epochs:
                # é¢„çƒ­é˜¶æ®µï¼šä»è¾ƒé«˜çš„åŸºç¡€å€¼å¼€å§‹çº¿æ€§å¢é•¿åˆ°1.0
                base_ratio = 0.1  # é¢„çƒ­æœŸèµ·å§‹æ¯”ä¾‹ï¼ˆè€Œé0ï¼‰
                warmup_ratio = base_ratio + (1.0 - base_ratio) * (
                    float(current_step) / float(max(1, self.config.warmup_epochs))
                )
                return warmup_ratio
            
            # Cosineé€€ç«é˜¶æ®µ
            progress = float(current_step - self.config.warmup_epochs) / float(
                max(1, self.config.num_epochs - self.config.warmup_epochs)
            )
            # æ”¹å–„çš„ä½™å¼¦é€€ç«ï¼šä¿æŒæ›´é«˜çš„æœ€å°å­¦ä¹ ç‡
            min_ratio = self.config.lr_min / self.config.learning_rate
            cosine_ratio = min_ratio + (1.0 - min_ratio) * 0.5 * (1.0 + math.cos(math.pi * progress))
            return max(min_ratio, cosine_ratio)
        
        return LambdaLR(self.optimizer, lr_lambda)
    
    def _get_kl_weight(self, epoch: int) -> float:
        """è®¡ç®—KLæ•£åº¦æƒé‡ï¼ˆKLé€€ç«ï¼‰"""
        if not self.config.kl_annealing:
            return self.config.kl_end_weight
        
        if epoch >= self.config.kl_annealing_epochs:
            return self.config.kl_end_weight
        
        # çº¿æ€§é€€ç«
        progress = epoch / self.config.kl_annealing_epochs
        weight = self.config.kl_start_weight + progress * (
            self.config.kl_end_weight - self.config.kl_start_weight
        )
        
        return weight
    
    def train_epoch(self, data: HeteroData) -> Dict[str, float]:
        """
        è®­ç»ƒä¸€ä¸ªepoch
        
        Args:
            data: è®­ç»ƒæ•°æ®ï¼ˆå•ä¸ªæœ‰åå·®å®ä¾‹ï¼‰
            
        Returns:
            epochç»Ÿè®¡ä¿¡æ¯
        """
        self.model.train()
        epoch_losses = {
            'total': 0.0,
            'bias': 0.0,
            'degree': 0.0,
            'logits': 0.0,
            'weights': 0.0,
            'kl': 0.0,
            'kl_raw': 0.0,  # æœªåŠ æƒçš„åŸå§‹KLæ•£åº¦
            'sparsity': 0.0,
            'reconstruction': 0.0  # é‡æ„æŸå¤±æ€»å’Œ
        }
        
        # æ·»åŠ æ¢¯åº¦å’Œå‚æ•°ç»Ÿè®¡
        gradient_stats = {
            'grad_norm': 0.0,
            'grad_max': 0.0,
            'param_norm': 0.0,
            'param_updates': 0.0,
            'nan_grads': 0,
            'inf_grads': 0
        }
        
        # KLæƒé‡ï¼ˆå¦‚æœæ¨¡å‹æ”¯æŒè¯¾ç¨‹å­¦ä¹ ï¼Œä¼šè¢«è¦†ç›–ï¼‰
        kl_weight = self._get_kl_weight(self.current_epoch)
        
        # æ›´æ–°æ¨¡å‹çš„è®­ç»ƒçŠ¶æ€ï¼ˆç”¨äºè¯¾ç¨‹å­¦ä¹ ï¼‰
        if hasattr(self.model, 'update_training_state'):
            self.model.update_training_state(self.current_epoch)
        else:
            # å…¼å®¹æ—§ç‰ˆæœ¬ï¼šç›´æ¥æ›´æ–°KLæƒé‡
            self.model.config.beta_kl = kl_weight
        
        # åœ¨ä¸€ä¸ªepochå†…å¤šæ¬¡ä½¿ç”¨åŒä¸€ä¸ªå®ä¾‹è¿›è¡Œè®­ç»ƒ
        iteration_bar = tqdm(
            range(self.config.iterations_per_epoch),
            desc=f"Epoch {self.current_epoch}",
            leave=False,
            ncols=80,
            disable=self.current_epoch % 10 != 0  # åªæœ‰æ¯10ä¸ªepochæ˜¾ç¤ºè¿­ä»£è¿›åº¦æ¡
        )
        
        # è·å–æ¢¯åº¦ç´¯ç§¯é…ç½®
        accumulation_steps = getattr(self.config, 'gradient_accumulation_steps', 1)
        
        for iteration in iteration_bar:
            # åªåœ¨ç´¯ç§¯å¼€å§‹æ—¶æ¸…é›¶æ¢¯åº¦
            if iteration % accumulation_steps == 0:
                self.optimizer.zero_grad()
            
            # æ•°æ®å¢å¼ºï¼ˆå¦‚æœå¯ç”¨ï¼‰
            augmented_data = self._apply_data_augmentation(data) if getattr(self.config, 'use_data_augmentation', False) else data
            
            # å‰å‘ä¼ æ’­ï¼ˆæ”¯æŒAMPæ··åˆç²¾åº¦ï¼‰
            try:
                if self.use_amp:
                    with autocast():
                        results = self.model(augmented_data, mode="train")
                        losses = results['losses']
                        
                        # æ·»åŠ ç¨€ç–æ€§æ­£åˆ™åŒ–ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                        if getattr(self.config, 'use_sparsity_regularization', False):
                            sparsity_loss = self._compute_sparsity_regularization(results, data)
                            sparsity_weight = getattr(self.config, 'sparsity_weight', 0.1)
                            losses['sparsity'] = sparsity_loss
                            losses['total'] = losses['total'] + sparsity_weight * sparsity_loss
                else:
                    results = self.model(augmented_data, mode="train")
                    losses = results['losses']
                    
                    # æ·»åŠ ç¨€ç–æ€§æ­£åˆ™åŒ–ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                    if getattr(self.config, 'use_sparsity_regularization', False):
                        sparsity_loss = self._compute_sparsity_regularization(results, data)
                        sparsity_weight = getattr(self.config, 'sparsity_weight', 0.1)
                        losses['sparsity'] = sparsity_loss
                        losses['total'] = losses['total'] + sparsity_weight * sparsity_loss
                    
            except RuntimeError as e:
                if "Expected all tensors to be on the same device" in str(e):
                    print(f"è®¾å¤‡é”™è¯¯è¯¦æƒ…: {e}")
                    print(f"æ•°æ®è®¾å¤‡çŠ¶æ€:")
                    print(f"  constraint.x device: {data['constraint'].x.device}")
                    print(f"  variable.x device: {data['variable'].x.device}")
                    if hasattr(data, 'edge_index_dict'):
                        for key, edge_index in data.edge_index_dict.items():
                            print(f"  {key} edge_index device: {edge_index.device}")
                raise
            
            # åå‘ä¼ æ’­ï¼ˆæ”¯æŒAMPå’Œæ¢¯åº¦ç´¯ç§¯ï¼‰
            total_loss = losses['total']
            
            # æ¢¯åº¦ç´¯ç§¯ï¼šé™¤ä»¥ç´¯ç§¯æ­¥æ•°
            if accumulation_steps > 1:
                total_loss = total_loss / accumulation_steps
            
            # æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥ï¼šç¡®ä¿æŸå¤±æ˜¯æœ‰é™çš„
            if not torch.isfinite(total_loss):
                logger.warning(f"è¿­ä»£ {iteration}: æ£€æµ‹åˆ°éæœ‰é™æŸå¤± {total_loss.item()}ï¼Œè·³è¿‡è¯¥è¿­ä»£")
                continue
            
            if self.use_amp:
                # AMPåå‘ä¼ æ’­
                self.scaler.scale(total_loss).backward()
                
                # åªåœ¨ç´¯ç§¯å‘¨æœŸç»“æŸæ—¶è¿›è¡Œä¼˜åŒ–å™¨æ›´æ–°
                if (iteration + 1) % accumulation_steps == 0:
                    # æ™ºèƒ½æ¢¯åº¦æœ‰æ•ˆæ€§æ£€æŸ¥ï¼ˆå…è®¸å°‘é‡NaNï¼‰
                    grad_stats = self._analyze_gradient_health()
                    
                    # å¦‚æœNaNæ¢¯åº¦æ¯”ä¾‹è¿‡é«˜ï¼ˆ>20%ï¼‰ï¼Œè·³è¿‡æ›´æ–°
                    if grad_stats['nan_ratio'] > 0.2:
                        logger.warning(f"è¿­ä»£ {iteration}: NaNæ¢¯åº¦æ¯”ä¾‹è¿‡é«˜ {grad_stats['nan_ratio']:.3f}ï¼Œè·³è¿‡æ›´æ–°")
                        self.optimizer.zero_grad()
                        continue
                    
                    # å¦‚æœæœ‰å°‘é‡NaNæ¢¯åº¦ï¼ˆâ‰¤20%ï¼‰ï¼Œè¿›è¡Œé›¶å€¼æ›¿æ¢
                    if grad_stats['nan_ratio'] > 0.0:
                        logger.debug(f"è¿­ä»£ {iteration}: æ£€æµ‹åˆ° {grad_stats['nan_ratio']:.3f} NaNæ¢¯åº¦ï¼Œè¿›è¡Œé›¶å€¼æ›¿æ¢")
                        self._replace_nan_gradients()
                    
                    # æ£€æŸ¥æ¢¯åº¦æ˜¯å¦å…¨ä¸ºé›¶ï¼ˆå¯èƒ½è¡¨ç¤ºæ¢¯åº¦æ¶ˆå¤±ï¼‰
                    if grad_stats['zero_ratio'] > 0.9:
                        logger.warning(f"è¿­ä»£ {iteration}: æ¢¯åº¦å‡ ä¹å…¨ä¸ºé›¶ {grad_stats['zero_ratio']:.3f}ï¼Œå¯èƒ½å­˜åœ¨æ¢¯åº¦æ¶ˆå¤±é—®é¢˜")
                        # ä¸è·³è¿‡ï¼Œä½†è®°å½•è­¦å‘Š
                    
                    # æ¢¯åº¦è£å‰ªï¼ˆéœ€è¦å…ˆunscaleï¼‰
                    if self.config.grad_clip_norm > 0:
                        self.scaler.unscale_(self.optimizer)
                        
                        # å¼ºåŒ–æ¢¯åº¦è£å‰ªï¼ˆæ›´ä¿å®ˆçš„å€¼ï¼‰
                        actual_clip_norm = min(self.config.grad_clip_norm, 0.1)
                        grad_norm = torch.nn.utils.clip_grad_norm_(
                            self.model.parameters(), 
                            actual_clip_norm
                        )
                        
                        # å¦‚æœæ¢¯åº¦èŒƒæ•°è¿‡å¤§ï¼Œè·³è¿‡æ›´æ–°
                        if grad_norm > 10.0:
                            logger.warning(f"è¿­ä»£ {iteration}: æ¢¯åº¦èŒƒæ•°è¿‡å¤§ {grad_norm:.4f}ï¼Œè·³è¿‡æ›´æ–°")
                            self.optimizer.zero_grad()
                            continue
                    
                    # ä¼˜åŒ–å™¨æ­¥è¿›
                    self.scaler.step(self.optimizer)
                    self.scaler.update()
            else:
                # æ ‡å‡†åå‘ä¼ æ’­
                total_loss.backward()
                
                # åªåœ¨ç´¯ç§¯å‘¨æœŸç»“æŸæ—¶è¿›è¡Œä¼˜åŒ–å™¨æ›´æ–°
                if (iteration + 1) % accumulation_steps == 0:
                    # æ™ºèƒ½æ¢¯åº¦æœ‰æ•ˆæ€§æ£€æŸ¥ï¼ˆå…è®¸å°‘é‡NaNï¼‰
                    grad_stats = self._analyze_gradient_health()
                    
                    # å¦‚æœNaNæ¢¯åº¦æ¯”ä¾‹è¿‡é«˜ï¼ˆ>20%ï¼‰ï¼Œè·³è¿‡æ›´æ–°
                    if grad_stats['nan_ratio'] > 0.2:
                        logger.warning(f"è¿­ä»£ {iteration}: NaNæ¢¯åº¦æ¯”ä¾‹è¿‡é«˜ {grad_stats['nan_ratio']:.3f}ï¼Œè·³è¿‡æ›´æ–°")
                        self.optimizer.zero_grad()
                        continue
                    
                    # å¦‚æœæœ‰å°‘é‡NaNæ¢¯åº¦ï¼ˆâ‰¤20%ï¼‰ï¼Œè¿›è¡Œé›¶å€¼æ›¿æ¢
                    if grad_stats['nan_ratio'] > 0.0:
                        logger.debug(f"è¿­ä»£ {iteration}: æ£€æµ‹åˆ° {grad_stats['nan_ratio']:.3f} NaNæ¢¯åº¦ï¼Œè¿›è¡Œé›¶å€¼æ›¿æ¢")
                        self._replace_nan_gradients()
                    
                    # æ£€æŸ¥æ¢¯åº¦æ˜¯å¦å…¨ä¸ºé›¶ï¼ˆå¯èƒ½è¡¨ç¤ºæ¢¯åº¦æ¶ˆå¤±ï¼‰
                    if grad_stats['zero_ratio'] > 0.9:
                        logger.warning(f"è¿­ä»£ {iteration}: æ¢¯åº¦å‡ ä¹å…¨ä¸ºé›¶ {grad_stats['zero_ratio']:.3f}ï¼Œå¯èƒ½å­˜åœ¨æ¢¯åº¦æ¶ˆå¤±é—®é¢˜")
                    
                    # å¼ºåŒ–æ¢¯åº¦è£å‰ª
                    if self.config.grad_clip_norm > 0:
                        actual_clip_norm = min(self.config.grad_clip_norm, 0.1)
                        grad_norm = torch.nn.utils.clip_grad_norm_(
                            self.model.parameters(), 
                            actual_clip_norm
                        )
                        
                        # å¦‚æœæ¢¯åº¦èŒƒæ•°è¿‡å¤§ï¼Œè·³è¿‡æ›´æ–°
                        if grad_norm > 10.0:
                            logger.warning(f"è¿­ä»£ {iteration}: æ¢¯åº¦èŒƒæ•°è¿‡å¤§ {grad_norm:.4f}ï¼Œè·³è¿‡æ›´æ–°")
                            self.optimizer.zero_grad()
                            continue
                    
                    # ä¼˜åŒ–å™¨æ­¥è¿›
                    self.optimizer.step()
            
            # ç´¯è®¡æŸå¤±
            for key in epoch_losses:
                if key in losses:
                    epoch_losses[key] += losses[key].item()
            
            # è®¡ç®—åŸå§‹KLæ•£åº¦ï¼ˆæœªåŠ æƒï¼‰
            if 'kl' in losses and kl_weight > 0:
                epoch_losses['kl_raw'] += (losses['kl'].item() / kl_weight)
            
            # è®¡ç®—é‡æ„æŸå¤±æ€»å’Œ
            reconstruction_components = ['bias', 'degree', 'logits', 'weights']
            reconstruction_total = sum(losses[comp].item() for comp in reconstruction_components if comp in losses)
            epoch_losses['reconstruction'] += reconstruction_total
            
            # æ¢¯åº¦ç»Ÿè®¡è®¡ç®—
            grad_stats = self._compute_gradient_stats()
            for key, value in grad_stats.items():
                if key not in gradient_stats:
                    gradient_stats[key] = 0  # åˆå§‹åŒ–æ–°é”®
                gradient_stats[key] += value
            
            # æ›´æ–°è¿­ä»£è¿›åº¦æ¡
            if not iteration_bar.disable:
                iter_desc = f"Loss:{total_loss.item():.4f} GradNorm:{grad_stats.get('grad_norm', 0):.3f}"
                iteration_bar.set_postfix_str(iter_desc)
            
            # è®°å½•è¯¦ç»†æ—¥å¿—ï¼ˆå‡å°‘é¢‘ç‡ï¼‰
            if iteration % (self.config.log_interval * 5) == 0:
                logger.debug(
                    f"Epoch {self.current_epoch}, Iter {iteration}: "
                    f"Total = {total_loss.item():.6f}, "
                    f"Reconstruction = {reconstruction_total:.6f}, "
                    f"KL(raw) = {epoch_losses['kl_raw']/(iteration+1):.6f}, "
                    f"KL_weight = {kl_weight:.6f}, "
                    f"Grad_norm = {grad_stats.get('grad_norm', 0):.4f}"
                )
            
            self.current_iteration += 1
        
        # è®¡ç®—å¹³å‡æŸå¤±å’Œæ¢¯åº¦ç»Ÿè®¡
        for key in epoch_losses:
            epoch_losses[key] /= self.config.iterations_per_epoch
        
        for key in gradient_stats:
            if key not in ['nan_grads', 'inf_grads', 'zero_grads', 'finite_grads', 'total_params']:
                gradient_stats[key] /= self.config.iterations_per_epoch
        
        # åˆå¹¶æŸå¤±å’Œæ¢¯åº¦ç»Ÿè®¡
        combined_stats = {**epoch_losses, **gradient_stats}
        
        return combined_stats
    
    def _compute_gradient_stats(self) -> Dict[str, float]:
        """
        è®¡ç®—æ¢¯åº¦å’Œå‚æ•°ç»Ÿè®¡ä¿¡æ¯ï¼ˆå¢å¼ºç‰ˆï¼‰
        
        Returns:
            æ¢¯åº¦ç»Ÿè®¡å­—å…¸ï¼ŒåŒ…å«è¯¦ç»†çš„å¥åº·çŠ¶å†µåˆ†æ
        """
        stats = {
            'grad_norm': 0.0,
            'grad_max': 0.0,
            'param_norm': 0.0,
            'param_updates': 0.0,
            'nan_grads': 0,
            'inf_grads': 0,
            'zero_grads': 0,
            'finite_grads': 0,
            'nan_ratio': 0.0,
            'finite_ratio': 0.0,
            'zero_ratio': 0.0,
            'total_params': 0
        }
        
        total_grad_norm = 0.0
        total_param_norm = 0.0
        max_grad = 0.0
        nan_count = 0
        inf_count = 0
        zero_count = 0
        finite_count = 0
        total_grad_elements = 0
        param_count = 0
        
        for name, param in self.model.named_parameters():
            if param.grad is not None:
                param_count += 1
                grad_flat = param.grad.flatten()
                grad_elements = grad_flat.numel()
                total_grad_elements += grad_elements
                
                # è¯¦ç»†ç»Ÿè®¡å„ç§æ¢¯åº¦ç±»å‹
                nan_mask = torch.isnan(grad_flat)
                inf_mask = torch.isinf(grad_flat)
                zero_mask = (grad_flat == 0.0)
                finite_mask = torch.isfinite(grad_flat)
                
                nan_count += nan_mask.sum().item()
                inf_count += inf_mask.sum().item()
                zero_count += zero_mask.sum().item()
                finite_count += finite_mask.sum().item()
                
                # åªå¯¹æœ‰é™æ¢¯åº¦è®¡ç®—èŒƒæ•°
                finite_grads = grad_flat[finite_mask]
                if len(finite_grads) > 0:
                    grad_norm = torch.norm(finite_grads).item()
                    total_grad_norm += grad_norm ** 2
                    max_grad = max(max_grad, torch.max(torch.abs(finite_grads)).item())
                
                # å‚æ•°ç»Ÿè®¡
                param_norm = param.data.norm().item()
                total_param_norm += param_norm ** 2
        
        if total_grad_elements > 0:
            stats['grad_norm'] = (total_grad_norm ** 0.5)
            stats['grad_max'] = max_grad
            stats['param_norm'] = (total_param_norm ** 0.5)
            stats['nan_grads'] = nan_count
            stats['inf_grads'] = inf_count
            stats['zero_grads'] = zero_count
            stats['finite_grads'] = finite_count
            stats['total_params'] = total_grad_elements
            
            # è®¡ç®—æ¯”ä¾‹
            stats['nan_ratio'] = nan_count / total_grad_elements
            stats['finite_ratio'] = finite_count / total_grad_elements
            stats['zero_ratio'] = zero_count / total_grad_elements
        
        return stats
    
    def validate(self, data: HeteroData) -> Dict[str, float]:
        """
        éªŒè¯æ¨¡å‹
        
        Args:
            data: éªŒè¯æ•°æ®
            
        Returns:
            éªŒè¯ç»Ÿè®¡ä¿¡æ¯
        """
        self.model.eval()
        
        with torch.no_grad():
            # éªŒè¯æ—¶ä¹Ÿä½¿ç”¨è®­ç»ƒæ¨¡å¼æ¥è®¡ç®—æŸå¤±
            self.model.train()
            results = self.model(data, mode="train")
            losses = results['losses']
            self.model.eval()
            
            val_losses = {}
            kl_weight = self._get_kl_weight(self.current_epoch)
            
            for key, value in losses.items():
                # ç¡®ä¿æŸå¤±å€¼æ˜¯æœ‰é™çš„
                loss_value = value.item()
                if not torch.isfinite(torch.tensor(loss_value)):
                    logger.warning(f"éªŒè¯æŸå¤± {key} åŒ…å«éæœ‰é™å€¼: {loss_value}ï¼Œæ›¿æ¢ä¸ºå¤§æ•°å€¼")
                    loss_value = 1000.0 if key == 'total' else 100.0
                val_losses[key] = loss_value
            
            # è®¡ç®—åŸå§‹KLæ•£åº¦ï¼ˆæœªåŠ æƒï¼‰
            if 'kl' in val_losses and kl_weight > 0:
                val_losses['kl_raw'] = val_losses['kl'] / kl_weight
            else:
                val_losses['kl_raw'] = val_losses.get('kl', 0.0)
            
            # è®¡ç®—é‡æ„æŸå¤±æ€»å’Œ
            reconstruction_components = ['bias', 'degree', 'logits', 'weights']
            reconstruction_total = sum(val_losses.get(comp, 0.0) for comp in reconstruction_components)
            val_losses['reconstruction'] = reconstruction_total
        
        return val_losses
    
    def train(self, data: HeteroData) -> Dict[str, Any]:
        """
        å®Œæ•´è®­ç»ƒè¿‡ç¨‹
        
        Args:
            data: è®­ç»ƒæ•°æ®ï¼ˆå•ä¸ªæœ‰åå·®å®ä¾‹ï¼‰
            
        Returns:
            è®­ç»ƒç»“æœ
        """
        logger.info(f"å¼€å§‹è®­ç»ƒ - æ€»epochæ•°: {self.config.num_epochs}")
        
        # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
        data = data.to(self.device)
        
        # ä¿å­˜é…ç½®
        self._save_config()
        
        # è®­ç»ƒå¾ªç¯
        start_time = time.time()
        
        # åˆ›å»ºè¿›åº¦æ¡
        progress_bar = tqdm(
            range(self.config.num_epochs),
            desc="Training Progress",
            unit="epoch",
            ncols=120,
            leave=True
        )
        
        # å¼‚æ­¥è´¨é‡è¯„ä¼°æ‰§è¡Œå™¨
        quality_executor = ThreadPoolExecutor(max_workers=1)
        pending_quality_future = None
        
        for epoch in progress_bar:
            self.current_epoch = epoch
            
            # è®­ç»ƒä¸€ä¸ªepoch
            train_losses = self.train_epoch(data)
            
            # è®¡ç®—å½“å‰KLæƒé‡ï¼ˆåœ¨è¿™é‡Œå®šä¹‰ï¼Œç¡®ä¿ä½œç”¨åŸŸæ­£ç¡®ï¼‰
            current_kl_weight = self._get_kl_weight(epoch)
            
            # éªŒè¯
            if epoch % self.config.validation_frequency == 0:
                val_losses = self.validate(data)
                
                # æ›´æ–°å†å²è®°å½•
                self.training_history['train_loss'].append(train_losses['total'])
                self.training_history['val_loss'].append(val_losses['total'])
                self.training_history['learning_rate'].append(
                    self.optimizer.param_groups[0]['lr']
                )
                self.training_history['kl_weight'].append(
                    self._get_kl_weight(epoch)
                )
                
                # è¯¦ç»†æŸå¤±åˆ†è§£å†å²
                self.training_history['train_reconstruction'].append(train_losses.get('reconstruction', 0))
                self.training_history['train_kl_raw'].append(train_losses.get('kl_raw', 0))
                self.training_history['train_bias'].append(train_losses.get('bias', 0))
                self.training_history['train_degree'].append(train_losses.get('degree', 0))
                self.training_history['train_logits'].append(train_losses.get('logits', 0))
                self.training_history['train_weights'].append(train_losses.get('weights', 0))
                self.training_history['train_sparsity'].append(train_losses.get('sparsity', 0))
                
                self.training_history['val_reconstruction'].append(val_losses.get('reconstruction', 0))
                self.training_history['val_kl_raw'].append(val_losses.get('kl_raw', 0))
                
                # æ¢¯åº¦å’Œå‚æ•°ç»Ÿè®¡å†å²
                self.training_history['grad_norm'].append(train_losses.get('grad_norm', 0))
                self.training_history['grad_max'].append(train_losses.get('grad_max', 0))
                self.training_history['param_norm'].append(train_losses.get('param_norm', 0))
                self.training_history['nan_grads'].append(train_losses.get('nan_grads', 0))
                self.training_history['inf_grads'].append(train_losses.get('inf_grads', 0))
                
                # å­¦ä¹ ç‡è°ƒåº¦
                if self.scheduler:
                    if self.config.scheduler_type == "plateau":
                        self.scheduler.step(val_losses['total'])
                    else:
                        self.scheduler.step()
                
                # å¼‚æ­¥è´¨é‡è¯„ä¼°ï¼ˆä¿®å¤é˜»å¡é—®é¢˜ï¼‰
                quality_scores = {}
                should_evaluate = (
                    self.quality_evaluator and 
                    getattr(self.config, 'enable_quality_evaluation', True) and
                    epoch % getattr(self.config, 'quality_evaluation_frequency', 50) == 0 and
                    epoch > 100  # å‰100ä¸ªepochè·³è¿‡è´¨é‡è¯„ä¼°ï¼Œä¸“æ³¨è®­ç»ƒæ”¶æ•›
                )
                
                if should_evaluate:
                    # æ£€æŸ¥ä¸Šä¸€æ¬¡å¼‚æ­¥è¯„ä¼°æ˜¯å¦å®Œæˆ
                    if pending_quality_future and pending_quality_future.done():
                        try:
                            quality_scores = pending_quality_future.result(timeout=1.0)
                            logger.info(f"ğŸ“Š è´¨é‡è¯„ä¼°å®Œæˆ (Epoch {epoch-50})")
                        except Exception as e:
                            logger.warning(f"è´¨é‡è¯„ä¼°ç»“æœè·å–å¤±è´¥: {e}")
                            quality_scores = {}
                    
                    # å¯åŠ¨æ–°çš„å¼‚æ­¥è´¨é‡è¯„ä¼°
                    logger.info(f"ğŸ” å¯åŠ¨åå°è´¨é‡è¯„ä¼° (Epoch {epoch})...")
                    pending_quality_future = quality_executor.submit(
                        self._evaluate_generation_quality_safe, data, epoch
                    )
                    
                    # è®°å½•è´¨é‡è¯„ä¼°å†å²
                    if quality_scores:  # ç¡®ä¿quality_scoresä¸ä¸ºç©º
                        self.training_history['generation_quality'].append(quality_scores.get('overall_quality_score', 0.0))
                        self.training_history['validity_scores'].append(quality_scores.get('validity_score', 0.0))
                        self.training_history['diversity_scores'].append(quality_scores.get('diversity_score', 0.0))
                        self.training_history['similarity_scores'].append(quality_scores.get('graph_similarity', 0.0))
                    else:
                        # å¦‚æœè´¨é‡è¯„ä¼°å¤±è´¥ï¼Œå¡«å……é»˜è®¤å€¼
                        self.training_history['generation_quality'].append(0.0)
                        self.training_history['validity_scores'].append(0.0)
                        self.training_history['diversity_scores'].append(0.0)
                        self.training_history['similarity_scores'].append(0.0)
                
                # é«˜çº§Early Stoppingæ£€æŸ¥
                should_stop = False
                early_stopping_result = None
                
                if self.early_stopping_monitor:
                    # å‡†å¤‡æŒ‡æ ‡å­—å…¸
                    all_metrics = {
                        'val_loss': val_losses['total'],
                        'train_loss': train_losses['total'],
                        'kl_weight': current_kl_weight,
                        'grad_norm': train_losses.get('grad_norm', 0.0),
                        'reconstruction_loss': train_losses.get('reconstruction', 0.0),
                        'kl_raw': train_losses.get('kl_raw', 0.0),
                        'learning_rate': self.optimizer.param_groups[0]['lr']
                    }
                    
                    # æ·»åŠ è´¨é‡è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚æœæœ‰ï¼‰
                    if quality_scores:
                        all_metrics['generation_quality'] = quality_scores.get('overall_quality_score', 0.0)
                        all_metrics['graph_similarity'] = quality_scores.get('graph_similarity', 0.0)
                        all_metrics['diversity_score'] = quality_scores.get('diversity_score', 0.0)
                    
                    # æ›´æ–°Early Stoppingç›‘æ§å™¨
                    early_stopping_result = self.early_stopping_monitor.update(
                        epoch, 
                        all_metrics, 
                        model_state=self.model.state_dict()
                    )
                    
                    should_stop = early_stopping_result['should_stop']
                    
                    # è®°å½•Early Stoppingè¯¦ç»†ä¿¡æ¯
                    if epoch % 50 == 0 or should_stop:  # æ¯50ä¸ªepochæˆ–åœæ­¢æ—¶è®°å½•
                        logger.info(f"ğŸ” Early Stopping Analysis (Epoch {epoch}):")
                        logger.info(f"  â”œâ”€ Decision: {'STOP' if should_stop else 'CONTINUE'}")
                        logger.info(f"  â”œâ”€ Reason: {early_stopping_result['decision_reason']}")
                        logger.info(f"  â”œâ”€ Best Score: {early_stopping_result['best_score']:.6f} (Epoch {early_stopping_result['best_epoch']})")
                        logger.info(f"  â”œâ”€ Patience: {early_stopping_result['patience_counter']}/{early_stopping_result['current_patience']}")
                        
                        if early_stopping_result['trend_analysis']:
                            trend = early_stopping_result['trend_analysis']
                            logger.info(f"  â”œâ”€ Trend: {trend['trend']} (slope: {trend['slope']:.2e}, stability: {trend['stability']:.3f})")
                        
                        if early_stopping_result['quality_analysis']:
                            qa = early_stopping_result['quality_analysis']
                            logger.info(f"  â””â”€ Quality: {qa.get('quality_score', 'N/A'):.3f} (threshold: {self.early_stopping_monitor.config.quality_threshold})")
                    
                    if should_stop:
                        logger.warning(f"ğŸ›‘ é«˜çº§Early Stoppingè§¦å‘ (Epoch {epoch})")
                        logger.warning(f"  åŸå› : {early_stopping_result['decision_reason']}")
                        logger.warning(f"  ç½®ä¿¡åº¦: {early_stopping_result.get('confidence', 0.0):.3f}")
                        
                        # æ¢å¤æœ€ä½³æƒé‡ï¼ˆå¦‚æœé…ç½®å¯ç”¨ï¼‰
                        if self.early_stopping_monitor.should_restore_weights():
                            best_weights = self.early_stopping_monitor.get_best_weights()
                            if best_weights:
                                self.model.load_state_dict(best_weights)
                                logger.info(f"âœ… å·²æ¢å¤æœ€ä½³æ¨¡å‹æƒé‡ (æ¥è‡ªEpoch {early_stopping_result['best_epoch']})")
                        
                        break
                else:
                    # ä¼ ç»Ÿæ—©åœæ£€æŸ¥ï¼ˆå…¼å®¹æ€§ï¼‰
                    if self._check_early_stopping(val_losses['total']):
                        logger.info(f"ä¼ ç»Ÿæ—©åœåœ¨epoch {epoch}")
                        should_stop = True
                        break
                
                # å¢å¼ºçš„è¯¦ç»†æ—¥å¿—è¾“å‡º
                # current_kl_weight å·²åœ¨ä¸Šé¢å®šä¹‰
                
                # è®¡ç®—æŸå¤±ç»„ä»¶ç™¾åˆ†æ¯”
                train_total = train_losses['total']
                val_total = val_losses['total']
                
                recon_pct = (train_losses.get('reconstruction', 0) / train_total * 100) if train_total > 0 else 0
                kl_pct = (train_losses.get('kl', 0) / train_total * 100) if train_total > 0 else 0
                
                # æ›´æ–°è¿›åº¦æ¡æè¿°
                progress_desc = (
                    f"E{epoch:4d} | Loss:{train_total:.4f} | "
                    f"LR:{self.optimizer.param_groups[0]['lr']:.1e} | "
                    f"KL:{current_kl_weight:.3f}"
                )
                progress_bar.set_description(progress_desc)
                
                # ç®€åŒ–æ—¥å¿—è¾“å‡ºï¼ˆé¿å…è¿‡å¤šè¾“å‡ºå½±å“æ€§èƒ½ï¼‰
                if epoch % 10 == 0:  # æ¯10ä¸ªepochè¾“å‡ºä¸€æ¬¡è¯¦ç»†æ—¥å¿—
                    logger.info(
                        f"Epoch {epoch:4d} | "
                        f"Train Loss: {train_total:.6f} | "
                        f"Val Loss: {val_total:.6f} | "
                        f"LR: {self.optimizer.param_groups[0]['lr']:.2e} | "
                        f"KL Weight: {current_kl_weight:.4f}"
                    )
                
                # è¯¦ç»†æŸå¤±åˆ†è§£
                logger.info(
                    f"  â”œâ”€ Reconstruction: {train_losses.get('reconstruction', 0):.6f} ({recon_pct:.1f}%) "
                    f"[Bias: {train_losses.get('bias', 0):.4f}, Degree: {train_losses.get('degree', 0):.4f}, "
                    f"Logits: {train_losses.get('logits', 0):.4f}, Weights: {train_losses.get('weights', 0):.4f}]"
                )
                
                logger.info(
                    f"  â”œâ”€ KL Divergence: {train_losses.get('kl', 0):.6f} ({kl_pct:.1f}%) "
                    f"[Raw: {train_losses.get('kl_raw', 0):.6f}, Weight: {current_kl_weight:.4f}]"
                )
                
                # æ¢¯åº¦å’Œå‚æ•°ç»Ÿè®¡
                if 'grad_norm' in train_losses:
                    logger.info(
                        f"  â”œâ”€ Gradients: Norm={train_losses.get('grad_norm', 0):.4f}, "
                        f"Max={train_losses.get('grad_max', 0):.4f}, "
                        f"NaN={train_losses.get('nan_grads', 0)}, Inf={train_losses.get('inf_grads', 0)}"
                    )
                
                # å‚æ•°ç»Ÿè®¡
                if 'param_norm' in train_losses:
                    logger.info(
                        f"  â”œâ”€ Parameters: Norm={train_losses.get('param_norm', 0):.4f}"
                    )
                
                # è´¨é‡è¯„ä¼°ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
                if quality_scores:
                    logger.info(
                        f"  ğŸ¯ Quality Assessment: Overall={quality_scores.get('overall_quality_score', 0):.4f}, "
                        f"Similarity={quality_scores.get('graph_similarity', 0):.4f}, "
                        f"Diversity={quality_scores.get('diversity_score', 0):.4f}, "
                        f"Grade={quality_scores.get('benchmark_grade', 'N/A')}"
                    )
                
                # ç¨€ç–æ€§æŸå¤±ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if train_losses.get('sparsity', 0) > 0:
                    sparsity_pct = (train_losses['sparsity'] / train_total * 100) if train_total > 0 else 0
                    logger.info(f"  â””â”€ Sparsity: {train_losses['sparsity']:.6f} ({sparsity_pct:.1f}%)")
                
                # åœ¨çº¿è´¨é‡è¯„ä¼°ï¼ˆæ¯éš”ä¸€å®šepochæ‰§è¡Œï¼‰
                enable_quality_eval = getattr(self.config, 'enable_quality_evaluation', True)
                quality_eval_frequency = getattr(self.config, 'quality_evaluation_frequency', 100)
                if self.evaluator and enable_quality_eval and epoch % quality_eval_frequency == 0:
                    try:
                        num_samples = getattr(self.config, 'quality_samples_per_eval', 3)
                        quality_metrics = self.evaluator.evaluate_online_quality(
                            model=self.model,
                            original_data=data,
                            epoch=epoch,
                            num_samples=num_samples
                        )
                        
                        # æ›´æ–°è´¨é‡è¯„ä¼°å†å²
                        self.training_history['validity_score'].append(quality_metrics.get('validity_score', 0.0))
                        self.training_history['diversity_score'].append(quality_metrics.get('diversity_score', 0.0))
                        self.training_history['similarity_score'].append(quality_metrics.get('similarity_score', 0.0))
                        self.training_history['stability_score'].append(quality_metrics.get('stability_score', 0.0))
                        self.training_history['quality_overall'].append(quality_metrics.get('overall_quality', 0.0))
                        
                        # è®°å½•è´¨é‡è¯„ä¼°ç»“æœ
                        logger.info(
                            f"  â”œâ”€ Quality Assessment: "
                            f"Validity={quality_metrics.get('validity_score', 0):.3f}, "
                            f"Diversity={quality_metrics.get('diversity_score', 0):.3f}, "
                            f"Similarity={quality_metrics.get('similarity_score', 0):.3f}, "
                            f"Stability={quality_metrics.get('stability_score', 0):.3f}"
                        )
                        logger.info(f"  â””â”€ Overall Quality: {quality_metrics.get('overall_quality', 0):.3f}")
                        
                    except Exception as e:
                        logger.warning(f"åœ¨çº¿è´¨é‡è¯„ä¼°å¤±è´¥: {e}")
                        # å¡«å……é»˜è®¤å€¼ä»¥ä¿æŒå†å²è®°å½•ä¸€è‡´æ€§
                        self.training_history['validity_score'].append(0.0)
                        self.training_history['diversity_score'].append(0.0)
                        self.training_history['similarity_score'].append(0.0)
                        self.training_history['stability_score'].append(0.0)
                        self.training_history['quality_overall'].append(0.0)
            
            # ä¿å­˜æ¨¡å‹
            if epoch % self.config.save_frequency == 0 and epoch > 0:
                self._save_checkpoint(epoch, train_losses)
        
        # å…³é—­è¿›åº¦æ¡å’Œæ¸…ç†å¼‚æ­¥èµ„æº
        progress_bar.close()
        
        # ç­‰å¾…æœ€åä¸€æ¬¡è´¨é‡è¯„ä¼°å®Œæˆ
        if pending_quality_future:
            try:
                final_quality = pending_quality_future.result(timeout=30.0)
                logger.info("æœ€ç»ˆè´¨é‡è¯„ä¼°å®Œæˆ")
            except Exception as e:
                logger.warning(f"æœ€ç»ˆè´¨é‡è¯„ä¼°è¶…æ—¶æˆ–å¤±è´¥: {e}")
        
        quality_executor.shutdown(wait=True)
        
        # è®­ç»ƒå®Œæˆ
        training_time = time.time() - start_time
        logger.info(f"è®­ç»ƒå®Œæˆ - æ€»æ—¶é—´: {training_time:.2f}ç§’")
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        self._save_final_model()
        
        # ä¿å­˜è®­ç»ƒå†å²
        self._save_training_history()
        
        # ä¿å­˜Early StoppingçŠ¶æ€
        if self.early_stopping_monitor:
            early_stopping_save_path = self.save_dir / "early_stopping_state.json"
            self.early_stopping_monitor.save_state(str(early_stopping_save_path))
        
        # ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š
        return self._generate_training_report(training_time)
    
    def _check_early_stopping(self, val_loss: float) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥æ—©åœ"""
        if not self.config.use_early_stopping:
            return False
        
        # æ”¯æŒæ–°çš„é…ç½®å‚æ•°åç§°
        min_delta = getattr(self.config, 'min_delta', self.config.early_stopping_min_delta)
        
        if val_loss < self.best_loss - min_delta:
            self.best_loss = val_loss
            self.early_stopping_counter = 0
        else:
            self.early_stopping_counter += 1
        
        if self.early_stopping_counter >= self.config.early_stopping_patience:
            return True
        
        return False
    
    def _evaluate_generation_quality_safe(self, data: HeteroData, epoch: int) -> Dict[str, float]:
        """
        å®‰å…¨çš„è´¨é‡è¯„ä¼°æ–¹æ³•ï¼ˆç”¨äºå¼‚æ­¥æ‰§è¡Œï¼‰
        
        åŒ…å«å¼‚å¸¸å¤„ç†å’Œè¶…æ—¶æœºåˆ¶ï¼Œé¿å…é˜»å¡ä¸»è®­ç»ƒæµç¨‹
        """
        try:
            return self._evaluate_generation_quality(data, epoch)
        except Exception as e:
            logger.warning(f"åå°è´¨é‡è¯„ä¼°å¤±è´¥ (Epoch {epoch}): {e}")
            return {}
    
    def _evaluate_generation_quality(self, data: HeteroData, epoch: int) -> Dict[str, float]:
        """
        è¯„ä¼°ç”Ÿæˆè´¨é‡ï¼ˆæ–°å¢ï¼‰
        
        Args:
            data: åŸå§‹è®­ç»ƒæ•°æ®
            epoch: å½“å‰epoch
            
        Returns:
            è´¨é‡è¯„ä¼°ç»“æœ
        """
        try:
            if not self.quality_evaluator:
                return {}
            
            # å»¶è¿Ÿåˆå§‹åŒ–æ¨ç†å™¨
            if self.quality_inferencer is None:
                inference_config = InferenceConfig(
                    num_test_instances=getattr(self.config, 'quality_samples_per_eval', 3),
                    eta=0.1,
                    sample_from_prior=True,
                    constraint_selection_strategy="random"
                )
                self.quality_inferencer = G2MILPInference(self.model, inference_config)
            
            # åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼
            self.model.eval()
            
            # ç”Ÿæˆæµ‹è¯•æ ·æœ¬
            with torch.no_grad():
                inference_results = self.quality_inferencer.generate_instances(
                    data, 
                    num_samples=getattr(self.config, 'quality_samples_per_eval', 3)
                )
            
            # æ¢å¤è®­ç»ƒæ¨¡å¼
            self.model.train()
            
            # æå–ç”Ÿæˆæ•°æ®
            generated_data_list = inference_results['generated_instances']
            generation_info = inference_results['generation_info']
            
            # æ‰§è¡Œè´¨é‡è¯„ä¼°
            evaluation_results = self.quality_evaluator.evaluate_generation_quality(
                original_data=data,
                generated_data_list=generated_data_list,
                generation_info=generation_info
            )
            
            # æå–å…³é”®è´¨é‡æŒ‡æ ‡
            quality_summary = {
                'overall_quality_score': evaluation_results.get('overall_quality_score', 0.0),
                'graph_similarity': 0.0,
                'milp_similarity': 0.0,
                'diversity_score': 0.0,
                'validity_score': 1.0,  # é»˜è®¤å‡è®¾æœ‰æ•ˆï¼Œå¯ä»¥è¿›ä¸€æ­¥å®ç°
                'benchmark_grade': 'N/A'
            }
            
            # æå–å…·ä½“æŒ‡æ ‡
            if 'graph_similarity' in evaluation_results and 'weighted_average' in evaluation_results['graph_similarity']:
                quality_summary['graph_similarity'] = evaluation_results['graph_similarity']['weighted_average']
            
            if 'milp_similarity' in evaluation_results and 'overall_milp_similarity' in evaluation_results['milp_similarity']:
                quality_summary['milp_similarity'] = evaluation_results['milp_similarity']['overall_milp_similarity']
            
            if 'diversity_analysis' in evaluation_results and 'overall_diversity_score' in evaluation_results['diversity_analysis']:
                quality_summary['diversity_score'] = evaluation_results['diversity_analysis']['overall_diversity_score']
            
            if 'benchmark_comparison' in evaluation_results and 'summary' in evaluation_results['benchmark_comparison']:
                quality_summary['benchmark_grade'] = evaluation_results['benchmark_comparison']['summary']['grade']
            
            logger.debug(f"Epoch {epoch} è´¨é‡è¯„ä¼°å®Œæˆ - ç»¼åˆå¾—åˆ†: {quality_summary['overall_quality_score']:.4f}")
            
            return quality_summary
            
        except Exception as e:
            logger.warning(f"è´¨é‡è¯„ä¼°å¤±è´¥ (Epoch {epoch}): {e}")
            return {}
    
    def _apply_data_augmentation(self, data: HeteroData) -> HeteroData:
        """
        åº”ç”¨æ•°æ®å¢å¼ºæŠ€æœ¯
        
        ç­–ç•¥ï¼š
        1. ç‰¹å¾å™ªå£°æ³¨å…¥ï¼šå¯¹èŠ‚ç‚¹ç‰¹å¾æ·»åŠ å°å¹…é«˜æ–¯å™ªå£°
        2. è¾¹æƒé‡æ‰°åŠ¨ï¼šå¯¹è¾¹æƒé‡æ·»åŠ å°å¹…æ‰°åŠ¨
        3. ç»“æ„è½»å¾®ä¿®æ”¹ï¼šéšæœºé®ç›–å°‘é‡è¾¹ï¼ˆå¯é€‰ï¼‰
        
        Args:
            data: åŸå§‹å›¾æ•°æ®
            
        Returns:
            å¢å¼ºåçš„å›¾æ•°æ®
        """
        try:
            # åˆ›å»ºæ•°æ®å‰¯æœ¬
            augmented_data = data.clone()
            
            # 1. ç‰¹å¾å™ªå£°æ³¨å…¥
            feature_noise_std = getattr(self.config, 'feature_noise_std', 0.05)
            if feature_noise_std > 0:
                for node_type in ['constraint', 'variable']:
                    if node_type in augmented_data:
                        node_features = augmented_data[node_type].x
                        noise = torch.randn_like(node_features) * feature_noise_std
                        augmented_data[node_type].x = node_features + noise
            
            # 2. è¾¹ç‰¹å¾æ‰°åŠ¨ï¼ˆå¦‚æœå­˜åœ¨è¾¹ç‰¹å¾ï¼‰
            edge_noise_std = feature_noise_std * 0.5  # è¾¹ç‰¹å¾çš„å™ªå£°æ›´å°
            if hasattr(augmented_data, 'edge_attr_dict'):
                for edge_type, edge_attr in augmented_data.edge_attr_dict.items():
                    if edge_attr is not None and edge_noise_std > 0:
                        noise = torch.randn_like(edge_attr) * edge_noise_std
                        augmented_data.edge_attr_dict[edge_type] = edge_attr + noise
            
            # 3. è½»å¾®çš„ç»“æ„æ‰°åŠ¨ï¼ˆå¯é€‰ï¼Œæ¦‚ç‡å¾ˆä½ï¼‰
            edge_perturbation_prob = getattr(self.config, 'edge_perturbation_prob', 0.0)
            if edge_perturbation_prob > 0 and torch.rand(1).item() < edge_perturbation_prob:
                # å¯¹äºè®­ç»ƒç¨³å®šæ€§ï¼Œç›®å‰ä¸å®æ–½ç»“æ„æ‰°åŠ¨
                pass
            
            return augmented_data.to(self.device)
            
        except Exception as e:
            logger.warning(f"æ•°æ®å¢å¼ºå¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹æ•°æ®")
            return data
    
    def _compute_sparsity_regularization(self, model_results: Dict, data: HeteroData) -> torch.Tensor:
        """
        è®¡ç®—ç¨€ç–æ€§æ­£åˆ™åŒ–æŸå¤±
        
        é¼“åŠ±æ¨¡å‹ç”Ÿæˆä¸æºå›¾å…·æœ‰ç›¸ä¼¼ç¨€ç–æ€§çš„å›¾
        """
        try:
            # è·å–æºå›¾çš„è¾¹æ•°
            if hasattr(data, 'edge_index_dict'):
                source_edge_count = 0
                for edge_type, edge_index in data.edge_index_dict.items():
                    source_edge_count += edge_index.shape[1]
            else:
                source_edge_count = data.edge_index.shape[1] if hasattr(data, 'edge_index') else 1
            
            # è·å–æ¨¡å‹é¢„æµ‹çš„è¾¹æ¦‚ç‡ï¼ˆå‡è®¾åœ¨logitsé¢„æµ‹å™¨ä¸­ï¼‰
            if 'predictions' in model_results and 'logits' in model_results['predictions']:
                edge_logits = model_results['predictions']['logits']
                # ä½¿ç”¨sigmoidè·å–è¾¹æ¦‚ç‡
                edge_probs = torch.sigmoid(edge_logits)
                predicted_edge_count = torch.sum(edge_probs)
                
                # è®¡ç®—è¾¹æ•°å·®å¼‚çš„å¹³æ–¹æŸå¤±
                target_sparsity = getattr(self.config, 'target_sparsity', 0.1)
                expected_edges = source_edge_count * (1.0 + target_sparsity)
                sparsity_loss = torch.pow(predicted_edge_count - expected_edges, 2) / (expected_edges + 1e-8)
                
                return sparsity_loss
            else:
                # å¦‚æœæ— æ³•è·å–è¾¹é¢„æµ‹ï¼Œè¿”å›é›¶æŸå¤±
                return torch.tensor(0.0, device=self.device)
                
        except Exception as e:
            logger.warning(f"ç¨€ç–æ€§æ­£åˆ™åŒ–è®¡ç®—å¤±è´¥: {e}")
            return torch.tensor(0.0, device=self.device)
    
    def _save_config(self):
        """ä¿å­˜è®­ç»ƒé…ç½®"""
        config_path = self.save_dir / "training_config.json"
        
        config_dict = asdict(self.config)
        config_dict['model_config'] = {
            'constraint_feature_dim': self.model.constraint_feature_dim,
            'variable_feature_dim': self.model.variable_feature_dim,
            'edge_feature_dim': self.model.edge_feature_dim
        }
        
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config_dict, f, indent=2, ensure_ascii=False, default=str)
        
        logger.info(f"è®­ç»ƒé…ç½®å·²ä¿å­˜: {config_path}")
    
    def _save_checkpoint(self, epoch: int, losses: Dict[str, float]):
        """ä¿å­˜è®­ç»ƒæ£€æŸ¥ç‚¹"""
        checkpoint_path = self.save_dir / f"checkpoint_epoch_{epoch}.pth"
        
        torch.save({
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict() if self.scheduler else None,
            'losses': losses,
            'training_history': self.training_history,
            'best_loss': self.best_loss
        }, checkpoint_path)
        
        logger.debug(f"æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_path}")
    
    def _save_final_model(self):
        """ä¿å­˜æœ€ç»ˆæ¨¡å‹"""
        model_path = self.save_dir / "final_model.pth"
        self.model.save_model(str(model_path))
        
        logger.info(f"æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜: {model_path}")
    
    def _save_training_history(self):
        """ä¿å­˜è®­ç»ƒå†å²"""
        history_path = self.save_dir / "training_history.json"
        
        with open(history_path, 'w', encoding='utf-8') as f:
            json.dump(self.training_history, f, indent=2, ensure_ascii=False, default=str)
        
        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
        self._plot_training_curves()
        
        logger.info(f"è®­ç»ƒå†å²å·²ä¿å­˜: {history_path}")
    
    def _plot_training_curves(self):
        """ç»˜åˆ¶å¢å¼ºç‰ˆè®­ç»ƒæ›²çº¿"""
        try:
            # åˆ›å»ºæ›´å¤§çš„å›¾è¡¨æ¥å®¹çº³æ›´å¤šä¿¡æ¯
            fig, axes = plt.subplots(3, 3, figsize=(18, 12))
            
            # 1. æ€»æŸå¤±æ›²çº¿
            axes[0, 0].plot(self.training_history['train_loss'], label='Train Loss', linewidth=2)
            axes[0, 0].plot(self.training_history['val_loss'], label='Val Loss', linewidth=2)
            axes[0, 0].set_title('Total Loss Curves')
            axes[0, 0].set_xlabel('Validation Steps')
            axes[0, 0].set_ylabel('Loss')
            axes[0, 0].legend()
            axes[0, 0].grid(True, alpha=0.3)
            
            # 2. é‡æ„æŸå¤±åˆ†è§£
            axes[0, 1].plot(self.training_history['train_bias'], label='Bias', alpha=0.8)
            axes[0, 1].plot(self.training_history['train_degree'], label='Degree', alpha=0.8)
            axes[0, 1].plot(self.training_history['train_logits'], label='Logits', alpha=0.8)
            axes[0, 1].plot(self.training_history['train_weights'], label='Weights', alpha=0.8)
            axes[0, 1].set_title('Reconstruction Loss Components')
            axes[0, 1].set_xlabel('Validation Steps')
            axes[0, 1].set_ylabel('Loss')
            axes[0, 1].legend()
            axes[0, 1].grid(True, alpha=0.3)
            
            # 3. KLæ•£åº¦ï¼ˆåŸå§‹ vs åŠ æƒï¼‰
            axes[0, 2].plot(self.training_history['train_kl_raw'], label='KL Raw', alpha=0.8)
            axes[0, 2].plot(self.training_history['kl_weight'], label='KL Weight', alpha=0.8)
            kl_weighted = [raw * weight for raw, weight in zip(self.training_history['train_kl_raw'], self.training_history['kl_weight'])]
            axes[0, 2].plot(kl_weighted, label='KL Weighted', alpha=0.8)
            axes[0, 2].set_title('KL Divergence Analysis')
            axes[0, 2].set_xlabel('Validation Steps')
            axes[0, 2].set_ylabel('Value')
            axes[0, 2].legend()
            axes[0, 2].grid(True, alpha=0.3)
            
            # 4. å­¦ä¹ ç‡æ›²çº¿
            axes[1, 0].plot(self.training_history['learning_rate'], linewidth=2)
            axes[1, 0].set_title('Learning Rate Schedule')
            axes[1, 0].set_xlabel('Validation Steps')
            axes[1, 0].set_ylabel('Learning Rate')
            axes[1, 0].set_yscale('log')
            axes[1, 0].grid(True, alpha=0.3)
            
            # 5. æ¢¯åº¦ç»Ÿè®¡
            axes[1, 1].plot(self.training_history['grad_norm'], label='Grad Norm', alpha=0.8)
            axes[1, 1].plot(self.training_history['grad_max'], label='Grad Max', alpha=0.8)
            axes[1, 1].set_title('Gradient Statistics')
            axes[1, 1].set_xlabel('Validation Steps')
            axes[1, 1].set_ylabel('Gradient Magnitude')
            axes[1, 1].set_yscale('log')
            axes[1, 1].legend()
            axes[1, 1].grid(True, alpha=0.3)
            
            # 6. å‚æ•°èŒƒæ•°
            axes[1, 2].plot(self.training_history['param_norm'], linewidth=2, color='green')
            axes[1, 2].set_title('Parameter Norm')
            axes[1, 2].set_xlabel('Validation Steps')
            axes[1, 2].set_ylabel('Parameter Norm')
            axes[1, 2].grid(True, alpha=0.3)
            
            # 7. é‡æ„æŸå¤±å¯¹æ¯”ï¼ˆè®­ç»ƒ vs éªŒè¯ï¼‰
            axes[2, 0].plot(self.training_history['train_reconstruction'], label='Train Reconstruction', alpha=0.8)
            axes[2, 0].plot(self.training_history['val_reconstruction'], label='Val Reconstruction', alpha=0.8)
            axes[2, 0].set_title('Reconstruction Loss: Train vs Val')
            axes[2, 0].set_xlabel('Validation Steps')
            axes[2, 0].set_ylabel('Reconstruction Loss')
            axes[2, 0].legend()
            axes[2, 0].grid(True, alpha=0.3)
            
            # 8. æ•°å€¼ç¨³å®šæ€§ç›‘æ§
            axes[2, 1].bar(['NaN Grads', 'Inf Grads'], 
                          [sum(self.training_history['nan_grads']), sum(self.training_history['inf_grads'])],
                          color=['red', 'orange'], alpha=0.7)
            axes[2, 1].set_title('Numerical Stability')
            axes[2, 1].set_ylabel('Count')
            
            # 9. è´¨é‡è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if any(self.training_history['quality_overall']):
                # åˆ›å»ºè´¨é‡è¯„ä¼°çš„ç‹¬ç«‹æ­¥é•¿ï¼ˆå› ä¸ºä¸æ˜¯æ¯ä¸ªepochéƒ½è¯„ä¼°ï¼‰
                quality_steps = list(range(0, len(self.training_history['quality_overall'])))
                
                axes[2, 2].plot(quality_steps, self.training_history['validity_score'], 
                               label='Validity', alpha=0.8, marker='o', markersize=3)
                axes[2, 2].plot(quality_steps, self.training_history['diversity_score'], 
                               label='Diversity', alpha=0.8, marker='s', markersize=3)
                axes[2, 2].plot(quality_steps, self.training_history['similarity_score'], 
                               label='Similarity', alpha=0.8, marker='^', markersize=3)
                axes[2, 2].plot(quality_steps, self.training_history['quality_overall'], 
                               label='Overall', alpha=0.9, linewidth=2, color='red')
                axes[2, 2].set_title('Online Quality Assessment')
                axes[2, 2].set_xlabel('Quality Evaluation Steps')
                axes[2, 2].set_ylabel('Quality Score')
                axes[2, 2].legend()
                axes[2, 2].grid(True, alpha=0.3)
            elif any(self.training_history['train_sparsity']):
                # ç¨€ç–æ€§æŸå¤±
                axes[2, 2].plot(self.training_history['train_sparsity'], linewidth=2, color='purple')
                axes[2, 2].set_title('Sparsity Regularization')
                axes[2, 2].set_xlabel('Validation Steps')
                axes[2, 2].set_ylabel('Sparsity Loss')
                axes[2, 2].grid(True, alpha=0.3)
            else:
                # å¦‚æœæ²¡æœ‰è´¨é‡è¯„ä¼°å’Œç¨€ç–æ€§æŸå¤±ï¼Œæ˜¾ç¤ºæŸå¤±åˆ†å¸ƒ
                axes[2, 2].hist(self.training_history['train_loss'], bins=30, alpha=0.7, label='Train')
                axes[2, 2].hist(self.training_history['val_loss'], bins=30, alpha=0.7, label='Val')
                axes[2, 2].set_title('Loss Distribution')
                axes[2, 2].set_xlabel('Loss')
                axes[2, 2].set_ylabel('Frequency')
                axes[2, 2].legend()
            
            plt.tight_layout()
            plt.savefig(self.save_dir / "enhanced_training_curves.png", dpi=300, bbox_inches='tight')
            plt.close()
            
            logger.info("å¢å¼ºç‰ˆè®­ç»ƒæ›²çº¿å·²ä¿å­˜")
            
        except Exception as e:
            logger.warning(f"æ— æ³•ç»˜åˆ¶å¢å¼ºç‰ˆè®­ç»ƒæ›²çº¿: {e}")
            # å›é€€åˆ°åŸºç¡€ç‰ˆæœ¬
            self._plot_basic_training_curves()
    
    def _plot_basic_training_curves(self):
        """ç»˜åˆ¶åŸºç¡€è®­ç»ƒæ›²çº¿ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        try:
            fig, axes = plt.subplots(2, 2, figsize=(12, 8))
            
            # æ€»æŸå¤±æ›²çº¿
            axes[0, 0].plot(self.training_history['train_loss'], label='Train Loss')
            axes[0, 0].plot(self.training_history['val_loss'], label='Val Loss')
            axes[0, 0].set_title('Total Loss Curves')
            axes[0, 0].set_xlabel('Validation Steps')
            axes[0, 0].set_ylabel('Loss')
            axes[0, 0].legend()
            axes[0, 0].grid(True)
            
            # å­¦ä¹ ç‡æ›²çº¿
            axes[0, 1].plot(self.training_history['learning_rate'])
            axes[0, 1].set_title('Learning Rate')
            axes[0, 1].set_xlabel('Validation Steps')
            axes[0, 1].set_ylabel('Learning Rate')
            axes[0, 1].set_yscale('log')
            axes[0, 1].grid(True)
            
            # KLæƒé‡æ›²çº¿
            axes[1, 0].plot(self.training_history['kl_weight'])
            axes[1, 0].set_title('KL Weight (Î²)')
            axes[1, 0].set_xlabel('Validation Steps')
            axes[1, 0].set_ylabel('KL Weight')
            axes[1, 0].grid(True)
            
            # é‡æ„æŸå¤±
            axes[1, 1].plot(self.training_history['train_reconstruction'], label='Train Reconstruction')
            axes[1, 1].plot(self.training_history['val_reconstruction'], label='Val Reconstruction')
            axes[1, 1].set_title('Reconstruction Loss')
            axes[1, 1].set_xlabel('Validation Steps')
            axes[1, 1].set_ylabel('Loss')
            axes[1, 1].legend()
            axes[1, 1].grid(True)
            
            plt.tight_layout()
            plt.savefig(self.save_dir / "basic_training_curves.png", dpi=300, bbox_inches='tight')
            plt.close()
            
            logger.info("åŸºç¡€è®­ç»ƒæ›²çº¿å·²ä¿å­˜")
            
        except Exception as e:
            logger.warning(f"æ— æ³•ç»˜åˆ¶åŸºç¡€è®­ç»ƒæ›²çº¿: {e}")
    
    def _generate_training_report(self, training_time: float) -> Dict[str, Any]:
        """ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š"""
        report = {
            'training_summary': {
                'total_epochs': self.current_epoch + 1,
                'total_iterations': self.current_iteration,
                'training_time_seconds': training_time,
                'best_validation_loss': self.best_loss,
                'final_learning_rate': self.optimizer.param_groups[0]['lr']
            },
            'model_info': {
                'total_parameters': sum(p.numel() for p in self.model.parameters()),
                'trainable_parameters': sum(p.numel() for p in self.model.parameters() if p.requires_grad),
                'model_size_mb': sum(p.numel() * p.element_size() for p in self.model.parameters()) / 1024 / 1024
            },
            'config': asdict(self.config),
            'training_history': self.training_history
        }
        
        # æ·»åŠ Early Stoppingæ‘˜è¦
        if self.early_stopping_monitor:
            early_stopping_summary = self.early_stopping_monitor.get_summary()
            report['early_stopping'] = {
                'strategy': early_stopping_summary['config'].strategy.value,
                'best_score': early_stopping_summary['best_score'],
                'best_epoch': early_stopping_summary['best_epoch'],
                'total_improvements': early_stopping_summary['improvements'],
                'final_patience': early_stopping_summary['final_patience'],
                'statistics': early_stopping_summary['statistics']
            }
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = self.save_dir / "training_report.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)
        
        logger.info(f"è®­ç»ƒæŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        
        return report
    
    def _analyze_gradient_health(self) -> Dict[str, float]:
        """
        åˆ†ææ¢¯åº¦å¥åº·çŠ¶å†µï¼ˆæ–°å¢æ–¹æ³•ï¼‰
        
        Returns:
            åŒ…å«æ¢¯åº¦ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        total_params = 0
        nan_params = 0
        inf_params = 0
        zero_params = 0
        finite_params = 0
        grad_norm_sum = 0.0
        
        for param in self.model.parameters():
            if param.grad is not None:
                grad_flat = param.grad.flatten()
                param_count = grad_flat.numel()
                total_params += param_count
                
                # ç»Ÿè®¡NaNå’Œæ— é™å€¼
                nan_mask = torch.isnan(grad_flat)
                inf_mask = torch.isinf(grad_flat)
                zero_mask = (grad_flat == 0.0)
                finite_mask = torch.isfinite(grad_flat)
                
                nan_params += nan_mask.sum().item()
                inf_params += inf_mask.sum().item()
                zero_params += zero_mask.sum().item()
                finite_params += finite_mask.sum().item()
                
                # è®¡ç®—æœ‰é™æ¢¯åº¦çš„èŒƒæ•°
                finite_grads = grad_flat[finite_mask]
                if len(finite_grads) > 0:
                    grad_norm_sum += torch.norm(finite_grads).item() ** 2
        
        # è®¡ç®—æ¯”ä¾‹
        nan_ratio = nan_params / max(total_params, 1)
        inf_ratio = inf_params / max(total_params, 1)
        zero_ratio = zero_params / max(total_params, 1)
        finite_ratio = finite_params / max(total_params, 1)
        
        # è®¡ç®—æ€»æ¢¯åº¦èŒƒæ•°
        total_grad_norm = grad_norm_sum ** 0.5
        
        return {
            'nan_ratio': nan_ratio,
            'inf_ratio': inf_ratio,
            'zero_ratio': zero_ratio,
            'finite_ratio': finite_ratio,
            'total_params': total_params,
            'grad_norm': total_grad_norm,
            'nan_count': nan_params,
            'inf_count': inf_params,
            'zero_count': zero_params
        }
    
    def _replace_nan_gradients(self):
        """
        å°†NaNæ¢¯åº¦æ›¿æ¢ä¸ºé›¶å€¼ï¼ˆæ–°å¢æ–¹æ³•ï¼‰
        """
        replaced_count = 0
        
        for param in self.model.parameters():
            if param.grad is not None:
                nan_mask = torch.isnan(param.grad)
                if nan_mask.any():
                    param.grad[nan_mask] = 0.0
                    replaced_count += nan_mask.sum().item()
        
        if replaced_count > 0:
            logger.debug(f"å·²å°† {replaced_count} ä¸ªNaNæ¢¯åº¦æ›¿æ¢ä¸ºé›¶å€¼")
    
    def load_checkpoint(self, checkpoint_path: str) -> bool:
        """åŠ è½½è®­ç»ƒæ£€æŸ¥ç‚¹"""
        try:
            checkpoint = torch.load(checkpoint_path, map_location=self.device)
            
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
            
            if checkpoint['scheduler_state_dict'] and self.scheduler:
                self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
            
            self.current_epoch = checkpoint['epoch']
            self.training_history = checkpoint['training_history']
            self.best_loss = checkpoint['best_loss']
            
            logger.info(f"æ£€æŸ¥ç‚¹å·²åŠ è½½: {checkpoint_path}")
            return True
            
        except Exception as e:
            logger.error(f"æ£€æŸ¥ç‚¹åŠ è½½å¤±è´¥: {e}")
            return False


def create_trainer(model: G2MILPGenerator, 
                  config: TrainingConfig = None,
                  evaluator = None) -> G2MILPTrainer:
    """
    åˆ›å»ºG2MILPè®­ç»ƒå™¨çš„å·¥å‚å‡½æ•°
    
    Args:
        model: G2MILPç”Ÿæˆå™¨æ¨¡å‹
        config: è®­ç»ƒé…ç½®
        evaluator: åœ¨çº¿è´¨é‡è¯„ä¼°å™¨ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        G2MILPè®­ç»ƒå™¨å®ä¾‹
    """
    return G2MILPTrainer(model, config, evaluator)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("G2MILPè®­ç»ƒæ¨¡å—æµ‹è¯•")
    print("=" * 40)
    
    # åˆ›å»ºæµ‹è¯•é…ç½®
    training_config = TrainingConfig(
        num_epochs=100,
        iterations_per_epoch=10,
        learning_rate=1e-3,
        use_early_stopping=True,
        early_stopping_patience=20
    )
    
    print(f"è®­ç»ƒé…ç½®:")
    print(f"- Epochs: {training_config.num_epochs}")
    print(f"- Learning Rate: {training_config.learning_rate}")
    print(f"- Device: {training_config.device}")
    print(f"- Early Stopping: {training_config.use_early_stopping}")
    print("è®­ç»ƒå™¨é…ç½®åˆ›å»ºæˆåŠŸ!")