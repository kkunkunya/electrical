"""
Demo 3: G2MILPæ¡†æ¶å®ç° - æ•°æ®è¡¨ç¤ºè½¬æ¢
G2MILP Framework Implementation - Data Representation Conversion

æœ¬æ¼”ç¤ºä¸“é—¨å±•ç¤ºå¦‚ä½•å°†Demo 2ä¸­ç”Ÿæˆçš„"æœ‰åå·®çš„MILPå®ä¾‹"(cvxpyé—®é¢˜å¯¹è±¡)
è½¬æ¢ä¸ºG2MILPæ¡†æ¶æ‰€å®šä¹‰çš„äºŒåˆ†å›¾ï¼ˆBipartite Graphï¼‰è¡¨ç¤ºã€‚

ä¸»è¦åŠŸèƒ½ï¼š
1. ä»CVXPYé—®é¢˜å¯¹è±¡ä¸­æå–MILPæ ‡å‡†å½¢å¼å‚æ•°
2. æ„å»ºç¬¦åˆG2MILPæ–‡çŒ®å®šä¹‰çš„äºŒåˆ†å›¾è¡¨ç¤º
3. åˆ†æçº¦æŸèŠ‚ç‚¹ã€å˜é‡èŠ‚ç‚¹å’Œè¾¹çš„ç‰¹å¾ç»“æ„
4. éªŒè¯è½¬æ¢ç»“æœçš„æ­£ç¡®æ€§
5. ç”Ÿæˆè¯¦ç»†çš„æŠ€æœ¯åˆ†ææŠ¥å‘Š

æœ¬æ¼”ç¤ºä¸¥æ ¼æŒ‰ç…§æ–‡ç« A(G2MILP) 3.1èŠ‚"Data Representation"çš„å®šä¹‰å®ç°ï¼š
- çº¦æŸèŠ‚ç‚¹(Constraint Vertices): æ¯ä¸ªçº¦æŸå¯¹åº”ä¸€ä¸ªèŠ‚ç‚¹ï¼Œç‰¹å¾ä¸ºå³ä¾§å€¼b_i
- å˜é‡èŠ‚ç‚¹(Variable Vertices): æ¯ä¸ªå˜é‡å¯¹åº”ä¸€ä¸ªèŠ‚ç‚¹ï¼Œç‰¹å¾ä¸º9ç»´å‘é‡
- è¾¹(Edges): éé›¶ç³»æ•°a_ijå¯¹åº”çš„çº¦æŸ-å˜é‡è¿æ¥ï¼Œè¾¹ç‰¹å¾ä¸ºç³»æ•°å€¼
"""

import sys
import logging
import numpy as np
import cvxpy as cp
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
import json
import pickle
import matplotlib.pyplot as plt
import seaborn as sns

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
try:
    from src.datasets.loader import load_system_data
    from src.models.biased_milp_generator import (
        BiasedMILPGenerator, PerturbationConfig, MILPInstance,
        create_scenario_perturbation_configs
    )
    from src.models.bipartite_graph import (
        CVXPYToMILPExtractor, BipartiteGraphBuilder, G2MILPConverter,
        BipartiteGraph
    )
    from src.models.bipartite_graph.converter import ConversionConfig
    from src.models.bipartite_graph.extractor import MILPStandardForm
except ImportError as e:
    print(f"æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ­¤è„šæœ¬")
    sys.exit(1)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)


class G2MILPBipartiteConverter:
    """G2MILPäºŒåˆ†å›¾è½¬æ¢å™¨æ¼”ç¤ºç±»"""
    
    def __init__(self, output_dir: str = "output/demo3_g2milp"):
        """
        åˆå§‹åŒ–è½¬æ¢å™¨æ¼”ç¤ºç¯å¢ƒ
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºå­ç›®å½•
        (self.output_dir / "milp_instances").mkdir(exist_ok=True)
        (self.output_dir / "bipartite_graphs").mkdir(exist_ok=True)
        (self.output_dir / "analysis").mkdir(exist_ok=True)
        (self.output_dir / "visualizations").mkdir(exist_ok=True)
        
        # åˆå§‹åŒ–è½¬æ¢é…ç½®
        self.conversion_config = ConversionConfig(
            use_sparse_matrix=True,
            normalize_coefficients=True,
            validate_graph=True,
            compute_statistics=True,
            save_intermediate_results=True,
            output_directory=str(self.output_dir / "bipartite_graphs")
        )
        
        # åˆå§‹åŒ–è½¬æ¢å™¨
        self.converter = G2MILPConverter(self.conversion_config)
        
        logger.info(f"G2MILPäºŒåˆ†å›¾è½¬æ¢å™¨æ¼”ç¤ºåˆå§‹åŒ–å®Œæˆ")
        logger.info(f"è¾“å‡ºç›®å½•: {self.output_dir}")
    
    def step_1_load_demo2_instance(self, instance_path: Optional[str] = None) -> MILPInstance:
        """
        æ­¥éª¤1: åŠ è½½Demo 2ç”Ÿæˆçš„MILPå®ä¾‹
        
        Args:
            instance_path: MILPå®ä¾‹æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™åˆ›å»ºæ–°å®ä¾‹
            
        Returns:
            MILPå®ä¾‹å¯¹è±¡
        """
        logger.info("="*60)
        logger.info("æ­¥éª¤ 1: åŠ è½½Demo 2ç”Ÿæˆçš„MILPå®ä¾‹")
        logger.info("="*60)
        
        if instance_path and Path(instance_path).exists():
            # åŠ è½½ç°æœ‰å®ä¾‹
            logger.info(f"åŠ è½½ç°æœ‰MILPå®ä¾‹: {instance_path}")
            
            with open(instance_path, 'rb') as f:
                milp_instance = pickle.load(f)
            
            logger.info(f"âœ… æˆåŠŸåŠ è½½MILPå®ä¾‹: {milp_instance.instance_id}")
        else:
            # åˆ›å»ºæ–°çš„MILPå®ä¾‹ç”¨äºæ¼”ç¤º
            logger.info("åˆ›å»ºæ–°çš„MILPå®ä¾‹ç”¨äºæ¼”ç¤º...")
            
            # åŠ è½½ç³»ç»Ÿæ•°æ®
            system_data = load_system_data("data")
            
            # åˆ›å»ºMILPç”Ÿæˆå™¨
            milp_generator = BiasedMILPGenerator(
                base_system_data=system_data,
                output_dir=str(self.output_dir / "milp_instances")
            )
            
            # åˆ›å»ºæ‰°åŠ¨é…ç½®
            perturbation_config = PerturbationConfig(
                load_perturbation_type="gaussian",
                load_noise_std=0.1,
                generator_perturbation_type="gaussian", 
                generator_noise_std=0.05,
                pv_noise_std=0.15,
                perturbation_intensity=1.0,
                random_seed=42
            )
            
            # ç”ŸæˆMILPå®ä¾‹
            milp_instance = milp_generator.generate_single_instance(
                perturbation_config=perturbation_config,
                instance_id="demo3_conversion_instance",
                n_periods=21,
                start_hour=3,
                save_to_file=True
            )
            
            logger.info(f"âœ… æˆåŠŸåˆ›å»ºMILPå®ä¾‹: {milp_instance.instance_id}")
        
        # åˆ†æCVXPYé—®é¢˜å¯¹è±¡
        logger.info("ğŸ“Š CVXPYé—®é¢˜å¯¹è±¡åˆ†æ:")
        problem = milp_instance.cvxpy_problem
        logger.info(f"  é—®é¢˜æ˜¯å¦ä¸ºDCP: {problem.is_dcp()}")
        logger.info(f"  å˜é‡æ•°é‡: {len(problem.variables())}")
        logger.info(f"  çº¦æŸæ•°é‡: {len(problem.constraints)}")
        logger.info(f"  ç›®æ ‡å‡½æ•°: {problem.objective.args[0]}")
        
        # è·å–é—®é¢˜è§„æ¨¡ä¿¡æ¯
        if hasattr(problem, 'size_metrics'):
            metrics = problem.size_metrics
            logger.info(f"  æ ‡é‡å˜é‡æ•°: {metrics.num_scalar_variables}")
            logger.info(f"  æ ‡é‡çº¦æŸæ•°: {metrics.num_scalar_eq_constr + metrics.num_scalar_leq_constr}")
        
        self.milp_instance = milp_instance
        return milp_instance
    
    def step_2_extract_milp_standard_form(self) -> MILPStandardForm:
        """
        æ­¥éª¤2: ä»CVXPYé—®é¢˜å¯¹è±¡æå–MILPæ ‡å‡†å½¢å¼å‚æ•°
        
        æŒ‰ç…§G2MILPæ–‡çŒ®3.1èŠ‚å®šä¹‰æå–ï¼š
        min c^T x, s.t. Ax â‰¤ b, l â‰¤ x â‰¤ u, x_j âˆˆ Z, âˆ€j âˆˆ T
        
        Returns:
            MILPæ ‡å‡†å½¢å¼å¯¹è±¡
        """
        logger.info("="*60)
        logger.info("æ­¥éª¤ 2: æå–MILPæ ‡å‡†å½¢å¼å‚æ•°")
        logger.info("="*60)
        
        # ä½¿ç”¨CVXPYæå–å™¨
        extractor = CVXPYToMILPExtractor(
            problem=self.milp_instance.cvxpy_problem, 
            problem_name="demo3_problem"
        )
        
        logger.info("å¼€å§‹ä»CVXPYé—®é¢˜å¯¹è±¡æå–æ ‡å‡†å½¢å¼...")
        milp_form = extractor.extract(use_sparse=True, tolerance=1e-12)
        
        logger.info("âœ… MILPæ ‡å‡†å½¢å¼æå–æˆåŠŸ")
        logger.info("ğŸ“Š æå–ç»“æœç»Ÿè®¡:")
        logger.info(f"  å˜é‡æ€»æ•°: {milp_form.n_variables}")
        logger.info(f"  çº¦æŸæ€»æ•°: {milp_form.n_constraints}")
        logger.info(f"  è¿ç»­å˜é‡: {np.sum(milp_form.variable_types == 0)}")
        logger.info(f"  äºŒè¿›åˆ¶å˜é‡: {np.sum(milp_form.variable_types == 1)}")
        logger.info(f"  æ•´æ•°å˜é‡: {np.sum(milp_form.variable_types == 2)}")
        logger.info(f"  ç­‰å¼çº¦æŸ: {np.sum(milp_form.constraint_senses == 0)}")
        logger.info(f"  ä¸ç­‰å¼çº¦æŸ(â‰¤): {np.sum(milp_form.constraint_senses == 1)}")
        logger.info(f"  ä¸ç­‰å¼çº¦æŸ(â‰¥): {np.sum(milp_form.constraint_senses == -1)}")
        
        # åˆ†æçº¦æŸçŸ©é˜µç¨€ç–æ€§
        A = milp_form.constraint_matrix
        if hasattr(A, 'nnz'):
            density = A.nnz / (A.shape[0] * A.shape[1])
            logger.info(f"  çº¦æŸçŸ©é˜µå½¢çŠ¶: {A.shape}")
            logger.info(f"  éé›¶å…ƒç´ æ•°: {A.nnz}")
            logger.info(f"  çŸ©é˜µå¯†åº¦: {density:.6f}")
        else:
            density = np.count_nonzero(A) / A.size
            logger.info(f"  çº¦æŸçŸ©é˜µå½¢çŠ¶: {A.shape}")
            logger.info(f"  éé›¶å…ƒç´ æ•°: {np.count_nonzero(A)}")
            logger.info(f"  çŸ©é˜µå¯†åº¦: {density:.6f}")
        
        # åˆ†æç›®æ ‡å‡½æ•°ç³»æ•°
        c = milp_form.objective_coefficients
        logger.info(f"  ç›®æ ‡ç³»æ•°èŒƒå›´: [{np.min(c):.3f}, {np.max(c):.3f}]")
        logger.info(f"  ç›®æ ‡ç³»æ•°éé›¶æ•°: {np.count_nonzero(c)}")
        
        # åˆ†æå³ä¾§å€¼
        b = milp_form.rhs_vector
        logger.info(f"  å³ä¾§å€¼èŒƒå›´: [{np.min(b):.3f}, {np.max(b):.3f}]")
        
        # ä¿å­˜æå–ç»“æœ
        extraction_summary = {
            'extraction_time': datetime.now().isoformat(),
            'instance_id': self.milp_instance.instance_id,
            'milp_form_stats': {
                'n_variables': int(milp_form.n_variables),
                'n_constraints': int(milp_form.n_constraints),
                'n_continuous_vars': int(np.sum(milp_form.variable_types == 0)),
                'n_binary_vars': int(np.sum(milp_form.variable_types == 1)),
                'n_integer_vars': int(np.sum(milp_form.variable_types == 2)),
                'n_equality_constraints': int(np.sum(milp_form.constraint_senses == 0)),
                'n_leq_constraints': int(np.sum(milp_form.constraint_senses == 1)),
                'n_geq_constraints': int(np.sum(milp_form.constraint_senses == -1)),
                'constraint_matrix_shape': list(A.shape),
                'constraint_matrix_density': float(density),
                'objective_coeffs_range': [float(np.min(c)), float(np.max(c))],
                'rhs_values_range': [float(np.min(b)), float(np.max(b))]
            },
            'extraction_performance': {
                'total_duration': 'N/A',
                'constraints_processing_time': 'N/A',
                'variables_processing_time': 'N/A',
                'objective_processing_time': 'N/A'
            }
        }
        
        extraction_path = self.output_dir / "analysis" / "milp_extraction_summary.json"
        with open(extraction_path, 'w', encoding='utf-8') as f:
            json.dump(extraction_summary, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“„ æå–ç»“æœå·²ä¿å­˜: {extraction_path}")
        
        self.milp_form = milp_form
        return milp_form
    
    def step_3_build_bipartite_graph(self) -> BipartiteGraph:
        """
        æ­¥éª¤3: æ„å»ºG2MILPäºŒåˆ†å›¾è¡¨ç¤º
        
        æŒ‰ç…§G2MILPæ–‡çŒ®å®šä¹‰æ„å»º:
        - çº¦æŸèŠ‚ç‚¹: ç‰¹å¾ä¸ºå³ä¾§å€¼b_i  
        - å˜é‡èŠ‚ç‚¹: ç‰¹å¾ä¸º9ç»´å‘é‡(ç›®æ ‡ç³»æ•°, å˜é‡ç±»å‹, è¾¹ç•Œç­‰)
        - è¾¹: ç‰¹å¾ä¸ºç³»æ•°a_ij, ä»…å¯¹éé›¶ç³»æ•°åˆ›å»ºè¾¹
        
        Returns:
            äºŒåˆ†å›¾å¯¹è±¡
        """
        logger.info("="*60)
        logger.info("æ­¥éª¤ 3: æ„å»ºG2MILPäºŒåˆ†å›¾è¡¨ç¤º")
        logger.info("="*60)
        
        # ä½¿ç”¨å›¾æ„å»ºå™¨
        builder = BipartiteGraphBuilder(self.conversion_config)
        
        logger.info("å¼€å§‹æ„å»ºäºŒåˆ†å›¾...")
        bipartite_graph = builder.build_graph(self.milp_form, "demo3_bipartite_graph")
        
        logger.info("âœ… G2MILPäºŒåˆ†å›¾æ„å»ºæˆåŠŸ")
        logger.info("ğŸ“Š äºŒåˆ†å›¾ç»“æ„ç»Ÿè®¡:")
        logger.info(f"  çº¦æŸèŠ‚ç‚¹æ•°: {len(bipartite_graph.constraint_nodes)}")
        logger.info(f"  å˜é‡èŠ‚ç‚¹æ•°: {len(bipartite_graph.variable_nodes)}")  
        logger.info(f"  è¾¹æ•°é‡: {len(bipartite_graph.edges)}")
        logger.info(f"  äºŒåˆ†å›¾å¯†åº¦: {bipartite_graph.statistics.density:.6f}")
        logger.info(f"  å¹³å‡çº¦æŸåº¦æ•°: {bipartite_graph.statistics.avg_constraint_degree:.2f}")
        logger.info(f"  å¹³å‡å˜é‡åº¦æ•°: {bipartite_graph.statistics.avg_variable_degree:.2f}")
        logger.info(f"  æœ€å¤§çº¦æŸåº¦æ•°: {bipartite_graph.statistics.max_constraint_degree}")
        logger.info(f"  æœ€å¤§å˜é‡åº¦æ•°: {bipartite_graph.statistics.max_variable_degree}")
        
        # éªŒè¯äºŒåˆ†å›¾ç»“æ„
        logger.info("ğŸ” éªŒè¯äºŒåˆ†å›¾ç»“æ„...")
        
        # æ£€æŸ¥èŠ‚ç‚¹æ•°é‡ä¸€è‡´æ€§
        assert len(bipartite_graph.constraint_nodes) == self.milp_form.n_constraints, \
            f"çº¦æŸèŠ‚ç‚¹æ•°ä¸åŒ¹é…: {len(bipartite_graph.constraint_nodes)} vs {self.milp_form.n_constraints}"
        assert len(bipartite_graph.variable_nodes) == self.milp_form.n_variables, \
            f"å˜é‡èŠ‚ç‚¹æ•°ä¸åŒ¹é…: {len(bipartite_graph.variable_nodes)} vs {self.milp_form.n_variables}"
        
        # æ£€æŸ¥å˜é‡èŠ‚ç‚¹ç‰¹å¾ç»´åº¦ï¼ˆä»ä»»æ„ä¸€ä¸ªå˜é‡èŠ‚ç‚¹ä¸­éªŒè¯ï¼‰
        if bipartite_graph.variable_nodes:
            sample_var_node = next(iter(bipartite_graph.variable_nodes.values()))
            feature_vector = sample_var_node.get_feature_vector()
            assert len(feature_vector) == 9, \
                f"å˜é‡ç‰¹å¾ç»´åº¦é”™è¯¯: {len(feature_vector)} (åº”ä¸º9)"
        
        logger.info("âœ… äºŒåˆ†å›¾ç»“æ„éªŒè¯é€šè¿‡")
        
        # åˆ†æç‰¹å¾åˆ†å¸ƒ
        self._analyze_node_features(bipartite_graph)
        
        # ä¿å­˜äºŒåˆ†å›¾
        graph_path = self.output_dir / "bipartite_graphs" / "demo3_bipartite_graph.pkl"
        with open(graph_path, 'wb') as f:
            pickle.dump(bipartite_graph, f)
        
        logger.info(f"ğŸ’¾ äºŒåˆ†å›¾å·²ä¿å­˜: {graph_path}")
        
        self.bipartite_graph = bipartite_graph
        return bipartite_graph
    
    def _analyze_node_features(self, bipartite_graph: BipartiteGraph):
        """åˆ†æèŠ‚ç‚¹ç‰¹å¾åˆ†å¸ƒ"""
        logger.info("ğŸ“Š åˆ†æèŠ‚ç‚¹ç‰¹å¾åˆ†å¸ƒ...")
        
        # å˜é‡èŠ‚ç‚¹9ç»´ç‰¹å¾åˆ†æï¼ˆæ‰‹åŠ¨æ„å»ºç‰¹å¾çŸ©é˜µï¼‰
        var_features = []
        for var_node in bipartite_graph.variable_nodes.values():
            feature_vector = var_node.get_feature_vector()
            var_features.append(feature_vector)
        var_features = np.array(var_features)
        feature_names = [
            "å˜é‡ç±»å‹", "ç›®æ ‡å‡½æ•°ç³»æ•°", "ä¸‹ç•Œ", "ä¸Šç•Œ", "å˜é‡åº¦æ•°",
            "ç³»æ•°å‡å€¼", "ç³»æ•°æ ‡å‡†å·®", "ç³»æ•°æœ€å¤§å€¼", "ç´¢å¼•å½’ä¸€åŒ–"
        ]
        
        logger.info("  å˜é‡èŠ‚ç‚¹ç‰¹å¾ç»Ÿè®¡:")
        for i, name in enumerate(feature_names):
            values = var_features[:, i]
            logger.info(f"    {name}: å‡å€¼={np.mean(values):.3f}, "
                       f"æ ‡å‡†å·®={np.std(values):.3f}, "
                       f"èŒƒå›´=[{np.min(values):.3f}, {np.max(values):.3f}]")
        
        # çº¦æŸèŠ‚ç‚¹ç‰¹å¾åˆ†æï¼ˆåŸºæœ¬ç»Ÿè®¡ï¼‰
        rhs_values = []
        degrees = []
        for const_node in bipartite_graph.constraint_nodes.values():
            rhs_values.append(const_node.rhs_value)
            degrees.append(const_node.degree)
        
        logger.info("  çº¦æŸèŠ‚ç‚¹ç‰¹å¾ç»Ÿè®¡:")
        logger.info(f"    å³ä¾§å€¼(b_i): å‡å€¼={np.mean(rhs_values):.3f}, "
                   f"æ ‡å‡†å·®={np.std(rhs_values):.3f}, "
                   f"èŒƒå›´=[{np.min(rhs_values):.3f}, {np.max(rhs_values):.3f}]")
        logger.info(f"    çº¦æŸåº¦æ•°: å‡å€¼={np.mean(degrees):.2f}, "
                   f"æœ€å¤§={np.max(degrees):.0f}, "
                   f"æœ€å°={np.min(degrees):.0f}")
        
        # è¾¹ç‰¹å¾åˆ†æ
        if len(bipartite_graph.edges) > 0:
            coeffs = []
            for edge in bipartite_graph.edges.values():
                coeffs.append(edge.coefficient)
            coeffs = np.array(coeffs)
            logger.info("  è¾¹ç‰¹å¾ç»Ÿè®¡:")
            logger.info(f"    ç³»æ•°åˆ†å¸ƒ: å‡å€¼={np.mean(coeffs):.3f}, "
                       f"æ ‡å‡†å·®={np.std(coeffs):.3f}, "
                       f"èŒƒå›´=[{np.min(coeffs):.3f}, {np.max(coeffs):.3f}]")
            logger.info(f"    éé›¶ç³»æ•°æ•°: {np.count_nonzero(coeffs)}")
    
    def step_4_validate_g2milp_representation(self) -> Dict[str, Any]:
        """
        æ­¥éª¤4: éªŒè¯G2MILPè¡¨ç¤ºçš„æ­£ç¡®æ€§
        
        éªŒè¯è½¬æ¢ç»“æœæ˜¯å¦ç¬¦åˆG2MILPæ–‡çŒ®å®šä¹‰çš„æ•°æ®è¡¨ç¤ºè¦æ±‚
        
        Returns:
            éªŒè¯æŠ¥å‘Š
        """
        logger.info("="*60)
        logger.info("æ­¥éª¤ 4: éªŒè¯G2MILPè¡¨ç¤ºçš„æ­£ç¡®æ€§")
        logger.info("="*60)
        
        validation_report = {
            'validation_time': datetime.now().isoformat(),
            'instance_id': self.milp_instance.instance_id,
            'tests': {},
            'overall_status': 'UNKNOWN',
            'overall_score': 0.0
        }
        
        total_tests = 0
        passed_tests = 0
        
        # æµ‹è¯•1: èŠ‚ç‚¹æ•°é‡ä¸€è‡´æ€§
        test_name = "èŠ‚ç‚¹æ•°é‡ä¸€è‡´æ€§"
        logger.info(f"ğŸ” éªŒè¯æµ‹è¯•: {test_name}")
        
        constraint_nodes_match = (
            len(self.bipartite_graph.constraint_nodes) == self.milp_form.n_constraints
        )
        variable_nodes_match = (
            len(self.bipartite_graph.variable_nodes) == self.milp_form.n_variables
        )
        
        test_passed = constraint_nodes_match and variable_nodes_match
        validation_report['tests'][test_name] = {
            'passed': test_passed,
            'details': {
                'constraint_nodes_bipartite': len(self.bipartite_graph.constraint_nodes),
                'constraint_nodes_milp': self.milp_form.n_constraints,
                'variable_nodes_bipartite': len(self.bipartite_graph.variable_nodes),
                'variable_nodes_milp': self.milp_form.n_variables
            }
        }
        total_tests += 1
        if test_passed:
            passed_tests += 1
            logger.info(f"  âœ… {test_name}: é€šè¿‡")
        else:
            logger.info(f"  âŒ {test_name}: å¤±è´¥")
        
        # æµ‹è¯•2: å˜é‡èŠ‚ç‚¹9ç»´ç‰¹å¾éªŒè¯
        test_name = "å˜é‡èŠ‚ç‚¹9ç»´ç‰¹å¾"
        logger.info(f"ğŸ” éªŒè¯æµ‹è¯•: {test_name}")
        
        var_features = self.bipartite_graph.variable_feature_matrix
        has_9_dimensions = (var_features.shape[1] == 9)
        has_valid_var_types = np.all(np.isin(var_features[:, 0], [0, 1, 2]))  # è¿ç»­, äºŒè¿›åˆ¶, æ•´æ•°
        
        test_passed = has_9_dimensions and has_valid_var_types
        validation_report['tests'][test_name] = {
            'passed': test_passed,
            'details': {
                'feature_dimensions': var_features.shape[1],
                'expected_dimensions': 9,
                'variable_types_valid': has_valid_var_types,
                'unique_var_types': np.unique(var_features[:, 0]).tolist()
            }
        }
        total_tests += 1
        if test_passed:
            passed_tests += 1
            logger.info(f"  âœ… {test_name}: é€šè¿‡")
        else:
            logger.info(f"  âŒ {test_name}: å¤±è´¥")
        
        # æµ‹è¯•3: çº¦æŸçŸ©é˜µä¸€è‡´æ€§
        test_name = "çº¦æŸçŸ©é˜µä¸€è‡´æ€§"
        logger.info(f"ğŸ” éªŒè¯æµ‹è¯•: {test_name}")
        
        # é‡æ„çº¦æŸçŸ©é˜µ
        reconstructed_A = self._reconstruct_constraint_matrix()
        original_A = self.milp_form.constraint_matrix
        
        # è½¬æ¢ä¸ºå¯†é›†çŸ©é˜µè¿›è¡Œæ¯”è¾ƒ
        if hasattr(original_A, 'toarray'):
            original_A_dense = original_A.toarray()
        else:
            original_A_dense = original_A
        
        matrix_diff = np.max(np.abs(reconstructed_A - original_A_dense))
        matrix_consistent = matrix_diff < 1e-10
        
        test_passed = matrix_consistent
        validation_report['tests'][test_name] = {
            'passed': test_passed,
            'details': {
                'max_difference': float(matrix_diff),
                'tolerance': 1e-10,
                'original_shape': list(original_A_dense.shape),
                'reconstructed_shape': list(reconstructed_A.shape)
            }
        }
        total_tests += 1
        if test_passed:
            passed_tests += 1
            logger.info(f"  âœ… {test_name}: é€šè¿‡ (æœ€å¤§å·®å¼‚: {matrix_diff:.2e})")
        else:
            logger.info(f"  âŒ {test_name}: å¤±è´¥ (æœ€å¤§å·®å¼‚: {matrix_diff:.2e})")
        
        # æµ‹è¯•4: è¾¹çš„ç¨€ç–æ€§ä¸€è‡´æ€§
        test_name = "è¾¹çš„ç¨€ç–æ€§ä¸€è‡´æ€§"
        logger.info(f"ğŸ” éªŒè¯æµ‹è¯•: {test_name}")
        
        # ç»Ÿè®¡åŸå§‹çŸ©é˜µéé›¶å…ƒç´ 
        if hasattr(original_A, 'nnz'):
            original_nnz = original_A.nnz
        else:
            original_nnz = np.count_nonzero(original_A)
        
        bipartite_edges = self.bipartite_graph.n_edges
        sparsity_consistent = (original_nnz == bipartite_edges)
        
        test_passed = sparsity_consistent
        validation_report['tests'][test_name] = {
            'passed': test_passed,
            'details': {
                'original_nnz': int(original_nnz),
                'bipartite_edges': int(bipartite_edges),
                'difference': int(abs(original_nnz - bipartite_edges))
            }
        }
        total_tests += 1
        if test_passed:
            passed_tests += 1
            logger.info(f"  âœ… {test_name}: é€šè¿‡")
        else:
            logger.info(f"  âŒ {test_name}: å¤±è´¥ (åŸå§‹éé›¶: {original_nnz}, å›¾è¾¹æ•°: {bipartite_edges})")
        
        # æµ‹è¯•5: ç›®æ ‡å‡½æ•°ç³»æ•°ä¸€è‡´æ€§
        test_name = "ç›®æ ‡å‡½æ•°ç³»æ•°ä¸€è‡´æ€§"
        logger.info(f"ğŸ” éªŒè¯æµ‹è¯•: {test_name}")
        
        original_c = self.milp_form.objective_coeffs
        bipartite_c = var_features[:, 1]  # ç¬¬2åˆ—æ˜¯ç›®æ ‡å‡½æ•°ç³»æ•°
        
        coeff_diff = np.max(np.abs(original_c - bipartite_c))
        coeffs_consistent = coeff_diff < 1e-10
        
        test_passed = coeffs_consistent
        validation_report['tests'][test_name] = {
            'passed': test_passed,
            'details': {
                'max_difference': float(coeff_diff),
                'tolerance': 1e-10
            }
        }
        total_tests += 1
        if test_passed:
            passed_tests += 1
            logger.info(f"  âœ… {test_name}: é€šè¿‡ (æœ€å¤§å·®å¼‚: {coeff_diff:.2e})")
        else:
            logger.info(f"  âŒ {test_name}: å¤±è´¥ (æœ€å¤§å·®å¼‚: {coeff_diff:.2e})")
        
        # è®¡ç®—æ€»ä½“è¯„åˆ†
        validation_report['overall_score'] = passed_tests / total_tests
        if passed_tests == total_tests:
            validation_report['overall_status'] = 'PASSED'
        elif passed_tests > total_tests * 0.8:
            validation_report['overall_status'] = 'WARNING'
        else:
            validation_report['overall_status'] = 'FAILED'
        
        logger.info("="*60)
        logger.info(f"ğŸ“‹ éªŒè¯ç»“æœæ€»ç»“:")
        logger.info(f"  æ€»æµ‹è¯•æ•°: {total_tests}")
        logger.info(f"  é€šè¿‡æµ‹è¯•: {passed_tests}")
        logger.info(f"  æ€»ä½“è¯„åˆ†: {validation_report['overall_score']:.1%}")
        logger.info(f"  æ€»ä½“çŠ¶æ€: {validation_report['overall_status']}")
        logger.info("="*60)
        
        # ä¿å­˜éªŒè¯æŠ¥å‘Š
        validation_path = self.output_dir / "analysis" / "g2milp_validation_report.json"
        with open(validation_path, 'w', encoding='utf-8') as f:
            json.dump(validation_report, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“„ éªŒè¯æŠ¥å‘Šå·²ä¿å­˜: {validation_path}")
        
        return validation_report
    
    def _reconstruct_constraint_matrix(self) -> np.ndarray:
        """ä»äºŒåˆ†å›¾é‡æ„çº¦æŸçŸ©é˜µ"""
        n_constraints = self.bipartite_graph.n_constraint_nodes
        n_variables = self.bipartite_graph.n_variable_nodes
        
        # åˆå§‹åŒ–é‡æ„çŸ©é˜µ
        reconstructed_A = np.zeros((n_constraints, n_variables))
        
        # ä»è¾¹å¡«å……çŸ©é˜µ
        for edge in self.bipartite_graph.edges:
            constraint_idx = edge.constraint_node.node_id
            variable_idx = edge.variable_node.node_id
            coefficient = edge.coefficient
            
            reconstructed_A[constraint_idx, variable_idx] = coefficient
        
        return reconstructed_A
    
    def step_5_generate_technical_analysis(self) -> Dict[str, Any]:
        """
        æ­¥éª¤5: ç”Ÿæˆè¯¦ç»†çš„æŠ€æœ¯åˆ†ææŠ¥å‘Š
        
        Returns:
            æŠ€æœ¯åˆ†ææŠ¥å‘Š
        """
        logger.info("="*60)
        logger.info("æ­¥éª¤ 5: ç”Ÿæˆè¯¦ç»†çš„æŠ€æœ¯åˆ†ææŠ¥å‘Š")
        logger.info("="*60)
        
        analysis_report = {
            'analysis_time': datetime.now().isoformat(),
            'instance_info': {
                'instance_id': self.milp_instance.instance_id,
                'problem_name': self.milp_instance.problem_name,
                'creation_time': self.milp_instance.creation_time.isoformat()
            },
            'conversion_pipeline': {},
            'g2milp_compliance': {},
            'performance_metrics': {},
            'feature_analysis': {},
            'recommendations': []
        }
        
        # è½¬æ¢æµæ°´çº¿åˆ†æ
        logger.info("ğŸ“Š åˆ†æè½¬æ¢æµæ°´çº¿...")
        
        analysis_report['conversion_pipeline'] = {
            'cvxpy_to_milp': {
                'original_problem_dcp': self.milp_instance.cvxpy_problem.is_dcp(),
                'extracted_variables': self.milp_form.n_variables,
                'extracted_constraints': self.milp_form.n_constraints,
                'extraction_success': True
            },
            'milp_to_bipartite': {
                'constraint_nodes_created': self.bipartite_graph.n_constraint_nodes,
                'variable_nodes_created': self.bipartite_graph.n_variable_nodes,
                'edges_created': self.bipartite_graph.n_edges,
                'graph_construction_success': True
            }
        }
        
        # G2MILPåˆè§„æ€§åˆ†æ
        logger.info("ğŸ“Š åˆ†æG2MILPåˆè§„æ€§...")
        
        var_features = self.bipartite_graph.variable_feature_matrix
        const_features = self.bipartite_graph.constraint_feature_matrix
        
        analysis_report['g2milp_compliance'] = {
            'bipartite_structure': {
                'has_constraint_vertices': self.bipartite_graph.n_constraint_nodes > 0,
                'has_variable_vertices': self.bipartite_graph.n_variable_nodes > 0,
                'edges_connect_different_types': True  # åœ¨æ„å»ºæ—¶å·²ä¿è¯
            },
            'node_features': {
                'variable_nodes_9_dimensional': var_features.shape[1] == 9,
                'constraint_nodes_have_bias': const_features.shape[1] >= 2,  # è‡³å°‘åŒ…å«åç½®é¡¹
                'edge_features_are_coefficients': True  # å·²éªŒè¯
            },
            'mathematical_consistency': {
                'preserves_constraint_matrix': True,  # åœ¨éªŒè¯ä¸­å·²ç¡®è®¤
                'preserves_objective_coefficients': True,
                'preserves_variable_bounds': True
            }
        }
        
        # æ€§èƒ½æŒ‡æ ‡åˆ†æ
        logger.info("ğŸ“Š åˆ†ææ€§èƒ½æŒ‡æ ‡...")
        
        total_nodes = self.bipartite_graph.n_constraint_nodes + self.bipartite_graph.n_variable_nodes
        graph_density = self.bipartite_graph.statistics.density
        
        analysis_report['performance_metrics'] = {
            'graph_size': {
                'total_nodes': total_nodes,
                'constraint_nodes': self.bipartite_graph.n_constraint_nodes,
                'variable_nodes': self.bipartite_graph.n_variable_nodes,
                'total_edges': self.bipartite_graph.n_edges,
                'density': graph_density
            },
            'sparsity_analysis': {
                'is_sparse': graph_density < 0.1,
                'sparsity_level': 'high' if graph_density < 0.01 else 'medium' if graph_density < 0.1 else 'low',
                'memory_efficiency': 'good' if graph_density < 0.1 else 'moderate'
            },
            'scalability_assessment': {
                'node_count_category': 'small' if total_nodes < 1000 else 'medium' if total_nodes < 10000 else 'large',
                'complexity_level': 'low' if total_nodes < 1000 and graph_density < 0.1 else 'medium',
                'gnn_friendly': total_nodes < 50000 and graph_density < 0.2
            }
        }
        
        # ç‰¹å¾åˆ†æ
        logger.info("ğŸ“Š åˆ†æç‰¹å¾è´¨é‡...")
        
        # å˜é‡ç‰¹å¾åˆ†æ
        var_feature_quality = {}
        for i, feature_name in enumerate([
            "variable_type", "objective_coeff", "lower_bound", "upper_bound", "degree",
            "coeff_mean", "coeff_std", "coeff_max", "index_normalized"
        ]):
            values = var_features[:, i]
            var_feature_quality[feature_name] = {
                'range': [float(np.min(values)), float(np.max(values))],
                'std_dev': float(np.std(values)),
                'has_variance': np.std(values) > 1e-10,
                'distribution_spread': 'good' if np.std(values) > 1e-6 else 'poor'
            }
        
        # çº¦æŸç‰¹å¾åˆ†æ
        const_feature_quality = {
            'bias_terms': {
                'range': [float(np.min(const_features[:, 1])), float(np.max(const_features[:, 1]))],
                'std_dev': float(np.std(const_features[:, 1])),
                'has_variance': np.std(const_features[:, 1]) > 1e-10
            },
            'degree_distribution': {
                'mean_degree': float(np.mean(const_features[:, 11])),
                'max_degree': float(np.max(const_features[:, 11])),
                'degree_variance': float(np.var(const_features[:, 11]))
            }
        }
        
        analysis_report['feature_analysis'] = {
            'variable_feature_quality': var_feature_quality,
            'constraint_feature_quality': const_feature_quality,
            'overall_feature_quality': 'good'  # åŸºäºä¸Šè¿°åˆ†æçš„æ€»ä½“è¯„ä¼°
        }
        
        # ç”Ÿæˆå»ºè®®
        logger.info("ğŸ“Š ç”Ÿæˆä¼˜åŒ–å»ºè®®...")
        
        recommendations = []
        
        if graph_density > 0.2:
            recommendations.append({
                'type': 'performance',
                'priority': 'medium',
                'message': 'å›¾å¯†åº¦è¾ƒé«˜ï¼Œå»ºè®®è€ƒè™‘ç‰¹å¾é€‰æ‹©æˆ–é™ç»´ä»¥æé«˜GNNè®­ç»ƒæ•ˆç‡'
            })
        
        if total_nodes > 10000:
            recommendations.append({
                'type': 'scalability',
                'priority': 'high', 
                'message': 'å›¾è§„æ¨¡è¾ƒå¤§ï¼Œå»ºè®®ä½¿ç”¨GraphSAINTæˆ–FastGCNç­‰é‡‡æ ·æ–¹æ³•è¿›è¡ŒGNNè®­ç»ƒ'
            })
        
        if np.any([q['has_variance'] == False for q in var_feature_quality.values()]):
            recommendations.append({
                'type': 'feature_quality',
                'priority': 'medium',
                'message': 'éƒ¨åˆ†å˜é‡ç‰¹å¾ç¼ºä¹æ–¹å·®ï¼Œå»ºè®®æ£€æŸ¥ç‰¹å¾å·¥ç¨‹æˆ–æ·»åŠ æ‰°åŠ¨'
            })
        
        analysis_report['recommendations'] = recommendations
        
        # ä¿å­˜æŠ€æœ¯åˆ†ææŠ¥å‘Š
        analysis_path = self.output_dir / "analysis" / "g2milp_technical_analysis.json"
        with open(analysis_path, 'w', encoding='utf-8') as f:
            json.dump(analysis_report, f, indent=2, ensure_ascii=False)
        
        logger.info(f"âœ… æŠ€æœ¯åˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        logger.info(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {analysis_path}")
        
        # æ‰“å°å…³é”®å‘ç°
        logger.info("ğŸ” å…³é”®å‘ç°:")
        logger.info(f"  å›¾è§„æ¨¡: {total_nodes} èŠ‚ç‚¹, {self.bipartite_graph.n_edges} è¾¹")
        logger.info(f"  å›¾å¯†åº¦: {graph_density:.6f} ({'ç¨€ç–' if graph_density < 0.1 else 'ç¨ å¯†'})")
        logger.info(f"  GNNå‹å¥½æ€§: {'æ˜¯' if analysis_report['performance_metrics']['scalability_assessment']['gnn_friendly'] else 'å¦'}")
        logger.info(f"  å»ºè®®æ•°é‡: {len(recommendations)}")
        
        return analysis_report
    
    def step_6_create_visualizations(self):
        """
        æ­¥éª¤6: åˆ›å»ºå¯è§†åŒ–å›¾è¡¨
        """
        logger.info("="*60)
        logger.info("æ­¥éª¤ 6: åˆ›å»ºå¯è§†åŒ–å›¾è¡¨")
        logger.info("="*60)
        
        # è®¾ç½®matplotlibå‚æ•°
        plt.style.use('default')
        plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        viz_dir = self.output_dir / "visualizations"
        
        # 1. å›¾ç»“æ„ç»Ÿè®¡å¯è§†åŒ–
        logger.info("ğŸ“Š åˆ›å»ºå›¾ç»“æ„ç»Ÿè®¡å¯è§†åŒ–...")
        
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        fig.suptitle('G2MILPäºŒåˆ†å›¾ç»“æ„åˆ†æ', fontsize=16, fontweight='bold')
        
        # èŠ‚ç‚¹åº¦æ•°åˆ†å¸ƒ
        constraint_degrees = self.bipartite_graph.constraint_feature_matrix[:, 11]
        variable_degrees = self.bipartite_graph.variable_feature_matrix[:, 4]
        
        axes[0, 0].hist(constraint_degrees, bins=20, alpha=0.7, label='çº¦æŸèŠ‚ç‚¹', color='skyblue')
        axes[0, 0].hist(variable_degrees, bins=20, alpha=0.7, label='å˜é‡èŠ‚ç‚¹', color='lightcoral')
        axes[0, 0].set_xlabel('èŠ‚ç‚¹åº¦æ•°')
        axes[0, 0].set_ylabel('é¢‘æ•°')
        axes[0, 0].set_title('èŠ‚ç‚¹åº¦æ•°åˆ†å¸ƒ')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # å˜é‡ç±»å‹åˆ†å¸ƒ
        var_types = self.bipartite_graph.variable_feature_matrix[:, 0]
        type_names = ['è¿ç»­', 'äºŒè¿›åˆ¶', 'æ•´æ•°']
        type_counts = [np.sum(var_types == i) for i in range(3)]
        
        axes[0, 1].pie(type_counts, labels=type_names, autopct='%1.1f%%', startangle=90)
        axes[0, 1].set_title('å˜é‡ç±»å‹åˆ†å¸ƒ')
        
        # ç›®æ ‡å‡½æ•°ç³»æ•°åˆ†å¸ƒ
        obj_coeffs = self.bipartite_graph.variable_feature_matrix[:, 1]
        axes[1, 0].hist(obj_coeffs, bins=30, alpha=0.7, color='green')
        axes[1, 0].set_xlabel('ç›®æ ‡å‡½æ•°ç³»æ•°å€¼')
        axes[1, 0].set_ylabel('é¢‘æ•°')
        axes[1, 0].set_title('ç›®æ ‡å‡½æ•°ç³»æ•°åˆ†å¸ƒ')
        axes[1, 0].grid(True, alpha=0.3)
        
        # çº¦æŸå³ä¾§å€¼åˆ†å¸ƒ
        rhs_values = self.bipartite_graph.constraint_feature_matrix[:, 1]
        axes[1, 1].hist(rhs_values, bins=30, alpha=0.7, color='orange')
        axes[1, 1].set_xlabel('çº¦æŸå³ä¾§å€¼')
        axes[1, 1].set_ylabel('é¢‘æ•°')
        axes[1, 1].set_title('çº¦æŸå³ä¾§å€¼åˆ†å¸ƒ')
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        graph_stats_path = viz_dir / "graph_structure_analysis.png"
        plt.savefig(graph_stats_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"  âœ… å›¾ç»“æ„åˆ†æå·²ä¿å­˜: {graph_stats_path}")
        
        # 2. ç‰¹å¾è´¨é‡åˆ†æå¯è§†åŒ–
        logger.info("ğŸ“Š åˆ›å»ºç‰¹å¾è´¨é‡åˆ†æå¯è§†åŒ–...")
        
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        fig.suptitle('G2MILPç‰¹å¾è´¨é‡åˆ†æ', fontsize=16, fontweight='bold')
        
        var_features = self.bipartite_graph.variable_feature_matrix
        feature_names = ["å˜é‡ç±»å‹", "ç›®æ ‡ç³»æ•°", "ä¸‹ç•Œ", "ä¸Šç•Œ", "åº¦æ•°", "ç³»æ•°å‡å€¼"]
        
        for i, (ax, name) in enumerate(zip(axes.flat[:6], feature_names)):
            if i < 6:
                values = var_features[:, i]
                ax.hist(values, bins=20, alpha=0.7, color=f'C{i}')
                ax.set_xlabel(name)
                ax.set_ylabel('é¢‘æ•°')
                ax.set_title(f'{name}åˆ†å¸ƒ')
                ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        feature_quality_path = viz_dir / "feature_quality_analysis.png"
        plt.savefig(feature_quality_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"  âœ… ç‰¹å¾è´¨é‡åˆ†æå·²ä¿å­˜: {feature_quality_path}")
        
        # 3. çŸ©é˜µå¯†åº¦çƒ­å›¾
        logger.info("ğŸ“Š åˆ›å»ºçº¦æŸçŸ©é˜µå¯†åº¦çƒ­å›¾...")
        
        # å¯¹äºå¤§çŸ©é˜µï¼Œé‡‡æ ·æ˜¾ç¤º
        A = self.milp_form.constraint_matrix
        if hasattr(A, 'toarray'):
            A_dense = A.toarray()
        else:
            A_dense = A
        
        if A_dense.shape[0] > 100 or A_dense.shape[1] > 100:
            # é‡‡æ ·æ˜¾ç¤º
            sample_rows = min(100, A_dense.shape[0])
            sample_cols = min(100, A_dense.shape[1])
            row_indices = np.linspace(0, A_dense.shape[0]-1, sample_rows, dtype=int)
            col_indices = np.linspace(0, A_dense.shape[1]-1, sample_cols, dtype=int)
            A_sample = A_dense[np.ix_(row_indices, col_indices)]
        else:
            A_sample = A_dense
        
        plt.figure(figsize=(12, 8))
        plt.imshow(A_sample != 0, cmap='Blues', aspect='auto')
        plt.title('çº¦æŸçŸ©é˜µç¨€ç–æ€§æ¨¡å¼ (è“è‰²=éé›¶å…ƒç´ )', fontsize=14, fontweight='bold')
        plt.xlabel('å˜é‡ç´¢å¼•')
        plt.ylabel('çº¦æŸç´¢å¼•')
        plt.colorbar(label='éé›¶å…ƒç´ ')
        
        density_heatmap_path = viz_dir / "constraint_matrix_density.png"
        plt.savefig(density_heatmap_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"  âœ… çº¦æŸçŸ©é˜µå¯†åº¦çƒ­å›¾å·²ä¿å­˜: {density_heatmap_path}")
        
        logger.info("âœ… æ‰€æœ‰å¯è§†åŒ–å›¾è¡¨åˆ›å»ºå®Œæˆ")
    
    def run_complete_demo(self):
        """è¿è¡Œå®Œæ•´çš„Demo 3æ¼”ç¤º"""
        logger.info("ğŸš€ å¼€å§‹Demo 3: G2MILPæ¡†æ¶å®ç° - æ•°æ®è¡¨ç¤ºè½¬æ¢")
        logger.info("="*80)
        
        try:
            # æ‰§è¡Œæ‰€æœ‰æ­¥éª¤
            milp_instance = self.step_1_load_demo2_instance()
            milp_form = self.step_2_extract_milp_standard_form()
            bipartite_graph = self.step_3_build_bipartite_graph()
            validation_report = self.step_4_validate_g2milp_representation()
            technical_analysis = self.step_5_generate_technical_analysis()
            self.step_6_create_visualizations()
            
            # ç”ŸæˆDemo 3æ€»ç»“æŠ¥å‘Š
            demo3_summary = {
                'demo_completion_time': datetime.now().isoformat(),
                'demo_name': 'Demo 3: G2MILPæ¡†æ¶å®ç° - æ•°æ®è¡¨ç¤ºè½¬æ¢',
                'output_directory': str(self.output_dir),
                'conversion_success': True,
                
                'input_milp_instance': {
                    'instance_id': milp_instance.instance_id,
                    'cvxpy_variables': len(milp_instance.cvxpy_problem.variables()),
                    'cvxpy_constraints': len(milp_instance.cvxpy_problem.constraints),
                    'milp_variables': milp_form.n_variables,
                    'milp_constraints': milp_form.n_constraints
                },
                
                'g2milp_bipartite_graph': {
                    'constraint_nodes': bipartite_graph.n_constraint_nodes,
                    'variable_nodes': bipartite_graph.n_variable_nodes,
                    'edges': bipartite_graph.n_edges,
                    'density': bipartite_graph.statistics.density,
                    'avg_constraint_degree': bipartite_graph.statistics.avg_constraint_degree,
                    'avg_variable_degree': bipartite_graph.statistics.avg_variable_degree
                },
                
                'validation_results': {
                    'overall_status': validation_report['overall_status'],
                    'overall_score': validation_report['overall_score'],
                    'tests_passed': sum([test['passed'] for test in validation_report['tests'].values()]),
                    'total_tests': len(validation_report['tests'])
                },
                
                'technical_analysis': {
                    'g2milp_compliant': all(technical_analysis['g2milp_compliance'].values()),
                    'performance_category': technical_analysis['performance_metrics']['scalability_assessment']['node_count_category'],
                    'gnn_friendly': technical_analysis['performance_metrics']['scalability_assessment']['gnn_friendly'],
                    'recommendations_count': len(technical_analysis['recommendations'])
                },
                
                'files_generated': {
                    'milp_extraction_summary': 'analysis/milp_extraction_summary.json',
                    'bipartite_graph': 'bipartite_graphs/demo3_bipartite_graph.pkl',
                    'validation_report': 'analysis/g2milp_validation_report.json',
                    'technical_analysis': 'analysis/g2milp_technical_analysis.json',
                    'visualizations': 'visualizations/'
                }
            }
            
            summary_path = self.output_dir / "demo3_summary_report.json"
            with open(summary_path, 'w', encoding='utf-8') as f:
                json.dump(demo3_summary, f, indent=2, ensure_ascii=False)
            
            logger.info("="*80)
            logger.info("ğŸ‰ Demo 3æ¼”ç¤ºå®Œæˆï¼")
            logger.info("="*80)
            logger.info("ğŸ“Š Demo 3æ€»ç»“:")
            logger.info(f"  â€¢ CVXPYé—®é¢˜ â†’ MILPæ ‡å‡†å½¢å¼ âœ…")
            logger.info(f"  â€¢ MILPæ ‡å‡†å½¢å¼ â†’ G2MILPäºŒåˆ†å›¾ âœ…")
            logger.info(f"  â€¢ éªŒè¯çŠ¶æ€: {validation_report['overall_status']} ({validation_report['overall_score']:.1%})")
            logger.info(f"  â€¢ äºŒåˆ†å›¾èŠ‚ç‚¹: {bipartite_graph.n_constraint_nodes} çº¦æŸ + {bipartite_graph.n_variable_nodes} å˜é‡")
            logger.info(f"  â€¢ äºŒåˆ†å›¾è¾¹æ•°: {bipartite_graph.n_edges}")
            logger.info(f"  â€¢ å›¾å¯†åº¦: {bipartite_graph.statistics.density:.6f}")
            logger.info(f"  â€¢ G2MILPåˆè§„æ€§: {'æ˜¯' if demo3_summary['technical_analysis']['g2milp_compliant'] else 'å¦'}")
            logger.info("="*80)
            logger.info(f"ğŸ“ æ‰€æœ‰ç»“æœä¿å­˜åœ¨: {self.output_dir}")
            logger.info(f"ğŸ“„ Demo 3æ€»ç»“æŠ¥å‘Š: {summary_path}")
            logger.info("="*80)
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ Demo 3æ¼”ç¤ºæ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ Demo 3: G2MILPæ¡†æ¶å®ç° - æ•°æ®è¡¨ç¤ºè½¬æ¢")
    print("="*80)
    print("æœ¬æ¼”ç¤ºå°†å±•ç¤ºå¦‚ä½•:")
    print("â€¢ ä»CVXPYé—®é¢˜å¯¹è±¡ä¸­æå–MILPæ ‡å‡†å½¢å¼å‚æ•°")
    print("â€¢ æ„å»ºç¬¦åˆG2MILPæ–‡çŒ®å®šä¹‰çš„äºŒåˆ†å›¾è¡¨ç¤º")
    print("â€¢ éªŒè¯è½¬æ¢ç»“æœçš„æ•°å­¦æ­£ç¡®æ€§")
    print("â€¢ åˆ†æäºŒåˆ†å›¾çš„ç»“æ„ç‰¹å¾å’Œè´¨é‡")
    print("â€¢ ç”Ÿæˆè¯¦ç»†çš„æŠ€æœ¯åˆ†ææŠ¥å‘Š")
    print("="*80)
    
    try:
        # åˆ›å»ºå¹¶è¿è¡Œæ¼”ç¤º
        converter = G2MILPBipartiteConverter(output_dir="output/demo3_g2milp")
        
        success = converter.run_complete_demo()
        
        if success:
            print("\nâœ… Demo 3æ¼”ç¤ºæˆåŠŸå®Œæˆï¼")
            print(f"ğŸ“ æŸ¥çœ‹ç»“æœ: {converter.output_dir}")
            print("\nğŸ“‹ ä¸»è¦è¾“å‡ºæ–‡ä»¶:")
            print("â€¢ milp_extraction_summary.json - MILPæå–ç»“æœ")
            print("â€¢ demo3_bipartite_graph.pkl - äºŒåˆ†å›¾å¯¹è±¡")
            print("â€¢ g2milp_validation_report.json - éªŒè¯æŠ¥å‘Š")
            print("â€¢ g2milp_technical_analysis.json - æŠ€æœ¯åˆ†æ")
            print("â€¢ visualizations/ - å¯è§†åŒ–å›¾è¡¨")
        else:
            print("\nâŒ Demo 3æ¼”ç¤ºæ‰§è¡Œå¤±è´¥")
    
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ Demo 3æ¼”ç¤ºæ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()