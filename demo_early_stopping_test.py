#!/usr/bin/env python3
"""
Demo Early Stoppingæµ‹è¯•è„šæœ¬
Demo Early Stopping Test Script

æµ‹è¯•æ–°å¢çš„é«˜çº§Early Stoppingæœºåˆ¶åœ¨Demo 4è®­ç»ƒä¸­çš„æ•ˆæœ
"""

import os
import sys
import torch
import numpy as np
from pathlib import Path
import logging
import time
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root / "src"))

# å¯¼å…¥å¿…è¦æ¨¡å—
from models.g2milp.early_stopping import (
    EarlyStoppingMonitor, 
    EarlyStoppingConfig, 
    EarlyStoppingStrategy,
    create_early_stopping_monitor
)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


def test_early_stopping_strategies():
    """æµ‹è¯•ä¸åŒEarly Stoppingç­–ç•¥"""
    logger.info("ğŸ§ª æµ‹è¯•ä¸åŒEarly Stoppingç­–ç•¥")
    logger.info("=" * 60)
    
    strategies = [
        "simple",
        "multi_metric", 
        "adaptive",
        "trend_analysis",
        "combined"
    ]
    
    results = {}
    
    for strategy in strategies:
        logger.info(f"\nğŸ“Š æµ‹è¯•ç­–ç•¥: {strategy}")
        logger.info("-" * 40)
        
        # åˆ›å»ºç›‘æ§å™¨
        monitor = create_early_stopping_monitor(
            strategy=strategy,
            patience=50,
            monitor_metric="val_loss",
            verbose=False  # å‡å°‘è¾“å‡º
        )
        
        # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
        start_time = time.time()
        epochs_trained = 0
        stop_reason = "max_epochs_reached"
        
        for epoch in range(200):  # æœ€å¤§200ä¸ªepoch
            # æ¨¡æ‹Ÿä¸åŒçš„è®­ç»ƒåœºæ™¯
            if strategy == "simple":
                # ç®€å•è¡°å‡æ¨¡å¼
                val_loss = 1.0 * np.exp(-epoch * 0.01) + np.random.normal(0, 0.01)
            elif strategy == "multi_metric":
                # å¤šæŒ‡æ ‡æ¨¡å¼
                val_loss = 1.0 - epoch * 0.002 + np.random.normal(0, 0.005)
                # åæœŸå‡ºç°è¿‡æ‹Ÿåˆ
                if epoch > 100:
                    val_loss += (epoch - 100) * 0.001
            elif strategy == "adaptive":
                # è‡ªé€‚åº”æ¨¡å¼ï¼šæœ‰æ—¶å¿«é€Ÿæ”¶æ•›ï¼Œæœ‰æ—¶ç¼“æ…¢
                if epoch < 50:
                    val_loss = 1.0 - epoch * 0.01 + np.random.normal(0, 0.01)
                else:
                    val_loss = 0.5 - (epoch - 50) * 0.0005 + np.random.normal(0, 0.002)
            elif strategy == "trend_analysis":
                # è¶‹åŠ¿åˆ†ææ¨¡å¼ï¼šæœ‰å¹³å°æœŸ
                if epoch < 30:
                    val_loss = 1.0 - epoch * 0.02 + np.random.normal(0, 0.01)
                elif epoch < 80:
                    val_loss = 0.4 + np.random.normal(0, 0.005)  # å¹³å°æœŸ
                else:
                    val_loss = 0.4 - (epoch - 80) * 0.001 + np.random.normal(0, 0.002)
            else:  # combined
                # ç»„åˆæ¨¡å¼ï¼šå¤æ‚çš„è®­ç»ƒæ›²çº¿
                base_loss = 1.0 * np.exp(-epoch * 0.008)
                noise = np.random.normal(0, 0.01)
                # æ·»åŠ å‘¨æœŸæ€§æ³¢åŠ¨
                periodic = 0.05 * np.sin(epoch * 0.1)
                val_loss = base_loss + noise + periodic
            
            # æ¨¡æ‹Ÿå…¶ä»–æŒ‡æ ‡
            train_loss = val_loss * 0.8 + np.random.normal(0, 0.005)
            grad_norm = 0.1 * np.exp(-epoch * 0.01) + np.random.normal(0, 0.001)
            generation_quality = min(0.9, epoch * 0.005) + np.random.normal(0, 0.02)
            
            metrics = {
                'val_loss': val_loss,
                'train_loss': train_loss,
                'grad_norm': grad_norm,
                'generation_quality': generation_quality,
                'kl_weight': min(1.0, epoch / 100),
                'learning_rate': 1e-4 * np.exp(-epoch * 0.01)
            }
            
            # æ›´æ–°ç›‘æ§å™¨
            result = monitor.update(epoch, metrics)
            
            epochs_trained = epoch + 1
            
            # æ£€æŸ¥åœæ­¢æ¡ä»¶
            if result['should_stop']:
                stop_reason = result['decision_reason']
                break
        
        # è®°å½•ç»“æœ
        training_time = time.time() - start_time
        summary = monitor.get_summary()
        
        results[strategy] = {
            'epochs_trained': epochs_trained,
            'stop_reason': stop_reason,
            'best_score': summary['best_score'],
            'best_epoch': summary['best_epoch'],
            'improvements': summary['improvements'],
            'training_time': training_time
        }
        
        logger.info(f"âœ“ ç­–ç•¥ {strategy} å®Œæˆ:")
        logger.info(f"  - è®­ç»ƒepochæ•°: {epochs_trained}")
        logger.info(f"  - åœæ­¢åŸå› : {stop_reason}")
        logger.info(f"  - æœ€ä½³å¾—åˆ†: {summary['best_score']:.6f} (epoch {summary['best_epoch']})")
        logger.info(f"  - æ”¹å–„æ¬¡æ•°: {summary['improvements']}")
        logger.info(f"  - è®­ç»ƒæ—¶é—´: {training_time:.2f}ç§’")
    
    return results


def test_quality_monitoring():
    """æµ‹è¯•è´¨é‡ç›‘æ§åŠŸèƒ½"""
    logger.info("\nğŸ¯ æµ‹è¯•è´¨é‡ç›‘æ§åŠŸèƒ½")
    logger.info("=" * 60)
    
    # åˆ›å»ºå¯ç”¨è´¨é‡ç›‘æ§çš„ç›‘æ§å™¨
    monitor = create_early_stopping_monitor(
        strategy="combined",
        patience=100,
        monitor_metric="val_loss",
        enable_quality_monitoring=True,
        quality_threshold=0.8,
        verbose=True
    )
    
    logger.info("æ¨¡æ‹Ÿè´¨é‡æ”¹å–„çš„è®­ç»ƒè¿‡ç¨‹...")
    
    for epoch in range(150):
        # æ¨¡æ‹Ÿè´¨é‡é€æ­¥æ”¹å–„çš„è¿‡ç¨‹
        val_loss = 1.0 * np.exp(-epoch * 0.008) + np.random.normal(0, 0.01)
        
        # è´¨é‡åˆ†é˜¶æ®µæ”¹å–„
        if epoch < 50:
            quality_score = 0.3 + epoch * 0.004  # æ…¢é€Ÿæ”¹å–„
        elif epoch < 100:
            quality_score = 0.5 + (epoch - 50) * 0.006  # ä¸­ç­‰æ”¹å–„
        else:
            quality_score = 0.8 + (epoch - 100) * 0.002  # æ¥è¿‘ç›®æ ‡
        
        quality_score = min(0.95, quality_score) + np.random.normal(0, 0.02)
        
        metrics = {
            'val_loss': val_loss,
            'train_loss': val_loss * 0.9,
            'generation_quality': quality_score,
            'graph_similarity': quality_score * 0.9,
            'diversity_score': quality_score * 0.8,
            'grad_norm': 0.1 * np.exp(-epoch * 0.01)
        }
        
        # æ›´æ–°ç›‘æ§å™¨
        result = monitor.update(epoch, metrics)
        
        # æ¯20ä¸ªepochè¾“å‡ºä¸€æ¬¡è´¨é‡æŠ¥å‘Š
        if epoch % 20 == 0:
            logger.info(f"Epoch {epoch:3d}: Quality={quality_score:.3f}, Val_Loss={val_loss:.4f}")
            if result['quality_analysis']:
                qa = result['quality_analysis']
                logger.info(f"  è´¨é‡åˆ†æ: å¾—åˆ†={qa.get('quality_score', 0):.3f}, "
                          f"è¶‹åŠ¿={qa.get('quality_trend', 'unknown')}")
        
        # æ£€æŸ¥åœæ­¢æ¡ä»¶
        if result['should_stop']:
            logger.info(f"\nâœ“ è´¨é‡ç›‘æ§åœæ­¢ (Epoch {epoch})")
            logger.info(f"  åœæ­¢åŸå› : {result['decision_reason']}")
            break
    
    # è¾“å‡ºè´¨é‡ç›‘æ§æ‘˜è¦
    summary = monitor.get_summary()
    logger.info(f"\nğŸ“Š è´¨é‡ç›‘æ§æ‘˜è¦:")
    logger.info(f"  - æœ€ä½³å¾—åˆ†: {summary['best_score']:.6f}")
    logger.info(f"  - æœ€ä½³epoch: {summary['best_epoch']}")
    logger.info(f"  - æ€»æ”¹å–„æ¬¡æ•°: {summary['improvements']}")


def test_adaptive_patience():
    """æµ‹è¯•è‡ªé€‚åº”patienceåŠŸèƒ½"""
    logger.info("\nâš™ï¸ æµ‹è¯•è‡ªé€‚åº”PatienceåŠŸèƒ½")
    logger.info("=" * 60)
    
    # åˆ›å»ºå¯ç”¨è‡ªé€‚åº”patienceçš„ç›‘æ§å™¨
    monitor = create_early_stopping_monitor(
        strategy="adaptive",
        patience=30,
        monitor_metric="val_loss",
        adaptive_patience=True,
        verbose=False
    )
    
    logger.info("æ¨¡æ‹Ÿä¸è§„å¾‹æ”¹å–„çš„è®­ç»ƒè¿‡ç¨‹...")
    
    patience_history = []
    
    for epoch in range(200):
        # æ¨¡æ‹Ÿä¸è§„å¾‹çš„æ”¹å–„æ¨¡å¼
        if epoch < 50:
            # å‰æœŸå¿«é€Ÿæ”¹å–„
            val_loss = 1.0 - epoch * 0.015 + np.random.normal(0, 0.01)
        elif epoch < 100:
            # ä¸­æœŸç¼“æ…¢æ”¹å–„
            val_loss = 0.25 - (epoch - 50) * 0.002 + np.random.normal(0, 0.005)
        else:
            # åæœŸææ…¢æ”¹å–„
            val_loss = 0.15 - (epoch - 100) * 0.0001 + np.random.normal(0, 0.002)
        
        metrics = {
            'val_loss': val_loss,
            'train_loss': val_loss * 0.9,
            'grad_norm': 0.1 * np.exp(-epoch * 0.01)
        }
        
        # æ›´æ–°ç›‘æ§å™¨
        result = monitor.update(epoch, metrics)
        patience_history.append(result['current_patience'])
        
        # æ¯25ä¸ªepochè®°å½•patienceå˜åŒ–
        if epoch % 25 == 0:
            logger.info(f"Epoch {epoch:3d}: Val_Loss={val_loss:.6f}, "
                      f"Patience={result['current_patience']}, "
                      f"Counter={result['patience_counter']}")
        
        # æ£€æŸ¥åœæ­¢æ¡ä»¶
        if result['should_stop']:
            logger.info(f"\nâœ“ è‡ªé€‚åº”åœæ­¢ (Epoch {epoch})")
            logger.info(f"  åœæ­¢åŸå› : {result['decision_reason']}")
            logger.info(f"  æœ€ç»ˆpatience: {result['current_patience']}")
            break
    
    # åˆ†æpatienceå˜åŒ–
    logger.info(f"\nğŸ“ˆ Patienceå˜åŒ–åˆ†æ:")
    logger.info(f"  - åˆå§‹patience: {patience_history[0]}")
    logger.info(f"  - æœ€å¤§patience: {max(patience_history)}")
    logger.info(f"  - æœ€å°patience: {min(patience_history)}")
    logger.info(f"  - æœ€ç»ˆpatience: {patience_history[-1]}")


def test_trend_analysis():
    """æµ‹è¯•è¶‹åŠ¿åˆ†æåŠŸèƒ½"""
    logger.info("\nğŸ“ˆ æµ‹è¯•è¶‹åŠ¿åˆ†æåŠŸèƒ½")
    logger.info("=" * 60)
    
    # åˆ›å»ºå¯ç”¨è¶‹åŠ¿åˆ†æçš„ç›‘æ§å™¨
    monitor = create_early_stopping_monitor(
        strategy="trend_analysis",
        patience=50,
        monitor_metric="val_loss",
        verbose=False
    )
    
    logger.info("æ¨¡æ‹Ÿå…·æœ‰æ˜æ˜¾è¶‹åŠ¿çš„è®­ç»ƒè¿‡ç¨‹...")
    
    # å®šä¹‰ä¸åŒçš„è¶‹åŠ¿é˜¶æ®µ
    trends = [
        ("ä¸‹é™è¶‹åŠ¿", lambda x: 1.0 - x * 0.02),     # å¿«é€Ÿä¸‹é™
        ("å¹³ç¨³æœŸ", lambda x: 0.3 + np.sin(x * 0.1) * 0.02),  # éœ‡è¡å¹³ç¨³
        ("ç¼“æ…¢ä¸‹é™", lambda x: 0.3 - x * 0.001),    # ææ…¢ä¸‹é™
        ("ä¸Šå‡è¶‹åŠ¿", lambda x: 0.2 + x * 0.005)     # è¿‡æ‹Ÿåˆä¸Šå‡
    ]
    
    epoch = 0
    for trend_name, trend_func in trends:
        logger.info(f"\nğŸ”„ è¿›å…¥{trend_name}é˜¶æ®µ...")
        
        trend_start_epoch = epoch
        for i in range(40):  # æ¯ä¸ªè¶‹åŠ¿40ä¸ªepoch
            val_loss = trend_func(i) + np.random.normal(0, 0.01)
            
            metrics = {
                'val_loss': val_loss,
                'train_loss': val_loss * 0.9,
                'grad_norm': 0.1 * np.exp(-epoch * 0.01)
            }
            
            # æ›´æ–°ç›‘æ§å™¨
            result = monitor.update(epoch, metrics)
            
            # æ¯10ä¸ªepochè¾“å‡ºè¶‹åŠ¿åˆ†æ
            if i % 10 == 0 and result['trend_analysis']:
                trend = result['trend_analysis']
                logger.info(f"  Epoch {epoch:3d}: è¶‹åŠ¿={trend['trend']}, "
                          f"æ–œç‡={trend['slope']:.2e}, ç¨³å®šæ€§={trend['stability']:.3f}")
            
            epoch += 1
            
            # æ£€æŸ¥åœæ­¢æ¡ä»¶
            if result['should_stop']:
                logger.info(f"\nâœ“ è¶‹åŠ¿åˆ†æåœæ­¢ (Epoch {epoch-1})")
                logger.info(f"  åœæ­¢åŸå› : {result['decision_reason']}")
                logger.info(f"  è¶‹åŠ¿é˜¶æ®µ: {trend_name}")
                return
    
    logger.info(f"\nğŸ“Š å®Œæˆæ‰€æœ‰è¶‹åŠ¿é˜¶æ®µæµ‹è¯• (æ€»è®¡ {epoch} epochs)")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("ğŸš€ å¯åŠ¨Early Stoppingæœºåˆ¶æµ‹è¯•")
    logger.info("=" * 80)
    
    # æ£€æŸ¥PyTorchå¯ç”¨æ€§
    logger.info(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    logger.info(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
    
    try:
        # 1. æµ‹è¯•ä¸åŒç­–ç•¥
        strategy_results = test_early_stopping_strategies()
        
        # 2. æµ‹è¯•è´¨é‡ç›‘æ§
        test_quality_monitoring()
        
        # 3. æµ‹è¯•è‡ªé€‚åº”patience
        test_adaptive_patience()
        
        # 4. æµ‹è¯•è¶‹åŠ¿åˆ†æ
        test_trend_analysis()
        
        # è¾“å‡ºæµ‹è¯•æ€»ç»“
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ¯ Early Stoppingæœºåˆ¶æµ‹è¯•æ€»ç»“")
        logger.info("=" * 80)
        
        logger.info("\nğŸ“Š ç­–ç•¥æ•ˆæœå¯¹æ¯”:")
        for strategy, result in strategy_results.items():
            logger.info(f"  {strategy:15s}: {result['epochs_trained']:3d} epochs, "
                      f"å¾—åˆ† {result['best_score']:.6f}, {result['improvements']:2d} æ¬¡æ”¹å–„")
        
        logger.info("\nâœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼ŒEarly Stoppingæœºåˆ¶å·¥ä½œæ­£å¸¸ï¼")
        logger.info("\nğŸ”§ é›†æˆå»ºè®®:")
        logger.info("  1. æ¨èä½¿ç”¨ 'combined' ç­–ç•¥ï¼Œç»¼åˆæ•ˆæœæœ€ä½³")
        logger.info("  2. å¯ç”¨è´¨é‡ç›‘æ§å¯ä»¥æå‡è®­ç»ƒæ•ˆæœ")
        logger.info("  3. è‡ªé€‚åº”patienceé€‚åˆé•¿æœŸè®­ç»ƒ")
        logger.info("  4. è¶‹åŠ¿åˆ†ææœ‰åŠ©äºè¯†åˆ«è¿‡æ‹Ÿåˆ")
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False
    
    return True


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)