#!/usr/bin/env python3
"""
Demo 4 æ¨ç†åŠŸèƒ½æµ‹è¯•è„šæœ¬
Demo 4 Inference Function Test Script

æµ‹è¯•ä¿®å¤åçš„æ¨ç†åŠŸèƒ½ï¼Œä½¿ç”¨å·²è®­ç»ƒçš„æ¨¡å‹è¿›è¡ŒMILPå®ä¾‹ç”Ÿæˆå’Œè´¨é‡è¯„ä¼°
"""

import os
import sys
import torch
import numpy as np
from pathlib import Path
import logging
from datetime import datetime
import traceback
import pickle

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root / "src"))

# å¯¼å…¥å¿…è¦æ¨¡å—
from models.g2milp.generator import G2MILPGenerator, GeneratorConfig
from models.g2milp.inference import G2MILPInference, InferenceConfig
from models.g2milp.evaluation import G2MILPEvaluator, EvaluationConfig
from models.bipartite_graph.format_converter import Demo3ToDemo4Converter

# è®¾ç½®æ—¥å¿—
def setup_logging():
    """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_dir = Path("output/demo4_g2milp/inference_test")
    log_dir.mkdir(parents=True, exist_ok=True)
    
    log_file = log_dir / f"inference_test_{timestamp}.log"
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    
    logger = logging.getLogger(__name__)
    logger.info(f"æ—¥å¿—æ–‡ä»¶: {log_file}")
    return logger

logger = setup_logging()


def load_trained_model(model_path: str, device: str = "cuda") -> G2MILPGenerator:
    """
    åŠ è½½å·²è®­ç»ƒçš„G2MILPæ¨¡å‹
    
    Args:
        model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
        device: è®¡ç®—è®¾å¤‡
        
    Returns:
        åŠ è½½çš„æ¨¡å‹å®ä¾‹
    """
    logger.info(f"åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹: {model_path}")
    
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
    
    # åŠ è½½æ¨¡å‹çŠ¶æ€ (PyTorch 2.7+éœ€è¦è®¾ç½®weights_only=False)
    checkpoint = torch.load(model_path, map_location=device, weights_only=False)
    
    # æå–æ¨¡å‹é…ç½®
    if 'config' in checkpoint:
        model_config = checkpoint['config']
        logger.info("ä»æ£€æŸ¥ç‚¹åŠ è½½æ¨¡å‹é…ç½®")
    elif 'model_config' in checkpoint:
        model_config = checkpoint['model_config']
        logger.info("ä»æ£€æŸ¥ç‚¹åŠ è½½æ¨¡å‹é…ç½®(æ—§æ ¼å¼)")
    else:
        # ä½¿ç”¨é»˜è®¤é…ç½®
        model_config = GeneratorConfig()
        logger.warning("ä½¿ç”¨é»˜è®¤æ¨¡å‹é…ç½®")
    
    # ä»æ£€æŸ¥ç‚¹è·å–ç‰¹å¾ç»´åº¦
    constraint_feature_dim = checkpoint.get('constraint_feature_dim', 16)
    variable_feature_dim = checkpoint.get('variable_feature_dim', 9)
    edge_feature_dim = checkpoint.get('edge_feature_dim', 8)
    
    # åˆ›å»ºæ¨¡å‹å®ä¾‹
    model = G2MILPGenerator(
        constraint_feature_dim=constraint_feature_dim,
        variable_feature_dim=variable_feature_dim,
        edge_feature_dim=edge_feature_dim,
        config=model_config
    )
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(device)
    model.eval()
    
    logger.info(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    logger.info(f"  - å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    logger.info(f"  - è®­ç»ƒepoch: {checkpoint.get('epoch', 'unknown')}")
    logger.info(f"  - è®­ç»ƒæŸå¤±: {checkpoint.get('train_loss', 'unknown')}")
    logger.info(f"  - éªŒè¯æŸå¤±: {checkpoint.get('val_loss', 'unknown')}")
    
    return model


def load_demo3_data(data_path: str) -> torch.Tensor:
    """
    åŠ è½½Demo 3çš„äºŒåˆ†å›¾æ•°æ®
    
    Args:
        data_path: æ•°æ®æ–‡ä»¶è·¯å¾„
        
    Returns:
        è½¬æ¢åçš„HeteroDataå¯¹è±¡
    """
    logger.info(f"åŠ è½½Demo 3æ•°æ®: {data_path}")
    
    if not os.path.exists(data_path):
        raise FileNotFoundError(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
    
    # åŠ è½½pickleæ–‡ä»¶
    with open(data_path, 'rb') as f:
        bipartite_graph = pickle.load(f)
    
    logger.info(f"åŸå§‹æ•°æ®ç±»å‹: {type(bipartite_graph)}")
    
    # è½¬æ¢ä¸ºHeteroDataæ ¼å¼
    converter = Demo3ToDemo4Converter()
    conversion_result = converter.convert_bipartite_graph(bipartite_graph)
    hetero_data = conversion_result['bipartite_data']
    
    logger.info(f"âœ… Demo 3æ•°æ®åŠ è½½æˆåŠŸ")
    logger.info(f"  - çº¦æŸèŠ‚ç‚¹: {hetero_data['constraint'].x.shape[0]}")
    logger.info(f"  - å˜é‡èŠ‚ç‚¹: {hetero_data['variable'].x.shape[0]}")
    logger.info(f"  - è¾¹æ•°: {hetero_data['constraint', 'connects', 'variable'].edge_index.shape[1]}")
    
    return hetero_data


def test_inference_pipeline(model: G2MILPGenerator, source_data: torch.Tensor):
    """
    æµ‹è¯•å®Œæ•´çš„æ¨ç†ç®¡é“
    
    Args:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        source_data: æºæ•°æ®
    """
    logger.info("ğŸ” å¼€å§‹æ¨ç†ç®¡é“æµ‹è¯•")
    logger.info("=" * 60)
    
    # åˆ›å»ºæ¨ç†é…ç½®
    inference_config = InferenceConfig(
        eta=0.1,
        num_test_instances=3,
        temperature=1.0,
        sample_from_prior=True,
        constraint_selection_strategy="random",
        diversity_boost=True,
        num_diverse_samples=5,
        compute_similarity_metrics=True,
        generate_comparison_report=True,
        experiment_name=f"inference_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    )
    
    # åˆ›å»ºæ¨ç†å™¨
    inference_engine = G2MILPInference(model, inference_config)
    
    # æ‰§è¡Œæ¨ç†æµ‹è¯•
    logger.info("æ‰§è¡Œæ¨ç†æµ‹è¯•...")
    
    try:
        # 1. å•å®ä¾‹ç”Ÿæˆæµ‹è¯•
        logger.info("ğŸ“‹ æµ‹è¯• 1: å•å®ä¾‹ç”Ÿæˆ")
        result = inference_engine.generate_single_instance(
            source_data=source_data,
            save_intermediate=True
        )
        
        if result:
            logger.info("âœ… å•å®ä¾‹ç”ŸæˆæˆåŠŸ")
            logger.info(f"  - ç”Ÿæˆè´¨é‡: {result.get('quality_score', 'N/A')}")
            logger.info(f"  - ç›¸ä¼¼åº¦: {result.get('similarity_score', 'N/A')}")
        else:
            logger.error("âŒ å•å®ä¾‹ç”Ÿæˆå¤±è´¥")
            return False
        
        # 2. æ‰¹é‡ç”Ÿæˆæµ‹è¯•
        logger.info("ğŸ“‹ æµ‹è¯• 2: æ‰¹é‡ç”Ÿæˆ")
        batch_results = inference_engine.generate_batch_instances(
            source_data=source_data,
            num_instances=inference_config.num_test_instances
        )
        
        if batch_results:
            logger.info(f"âœ… æ‰¹é‡ç”ŸæˆæˆåŠŸ ({len(batch_results)} ä¸ªå®ä¾‹)")
            
            # åˆ†ææ‰¹é‡ç»“æœ
            quality_scores = [r.get('quality_score', 0) for r in batch_results if r.get('quality_score')]
            similarity_scores = [r.get('similarity_score', 0) for r in batch_results if r.get('similarity_score')]
            
            if quality_scores:
                logger.info(f"  - å¹³å‡è´¨é‡: {np.mean(quality_scores):.4f}")
                logger.info(f"  - è´¨é‡èŒƒå›´: [{np.min(quality_scores):.4f}, {np.max(quality_scores):.4f}]")
            
            if similarity_scores:
                logger.info(f"  - å¹³å‡ç›¸ä¼¼åº¦: {np.mean(similarity_scores):.4f}")
                logger.info(f"  - ç›¸ä¼¼åº¦èŒƒå›´: [{np.min(similarity_scores):.4f}, {np.max(similarity_scores):.4f}]")
        else:
            logger.error("âŒ æ‰¹é‡ç”Ÿæˆå¤±è´¥")
            return False
        
        # 3. å¤šæ ·æ€§å¢å¼ºæµ‹è¯•
        logger.info("ğŸ“‹ æµ‹è¯• 3: å¤šæ ·æ€§å¢å¼ºç”Ÿæˆ")
        diversity_results = inference_engine.generate_diverse_instances(
            source_data=source_data,
            num_samples=inference_config.num_diverse_samples
        )
        
        if diversity_results:
            logger.info(f"âœ… å¤šæ ·æ€§ç”ŸæˆæˆåŠŸ ({len(diversity_results)} ä¸ªæ ·æœ¬)")
            
            # åˆ†æå¤šæ ·æ€§
            diversity_scores = [r.get('diversity_score', 0) for r in diversity_results if r.get('diversity_score')]
            if diversity_scores:
                logger.info(f"  - å¹³å‡å¤šæ ·æ€§: {np.mean(diversity_scores):.4f}")
                logger.info(f"  - å¤šæ ·æ€§èŒƒå›´: [{np.min(diversity_scores):.4f}, {np.max(diversity_scores):.4f}]")
        else:
            logger.error("âŒ å¤šæ ·æ€§ç”Ÿæˆå¤±è´¥")
            return False
        
        # 4. è´¨é‡è¯„ä¼°æµ‹è¯•
        logger.info("ğŸ“‹ æµ‹è¯• 4: è´¨é‡è¯„ä¼°")
        evaluation_results = inference_engine.evaluate_generated_instances(
            generated_instances=batch_results[:2],  # ä½¿ç”¨å‰ä¸¤ä¸ªå®ä¾‹
            source_data=source_data
        )
        
        if evaluation_results:
            logger.info("âœ… è´¨é‡è¯„ä¼°æˆåŠŸ")
            logger.info(f"  - ç»¼åˆå¾—åˆ†: {evaluation_results.get('overall_score', 'N/A')}")
            logger.info(f"  - æœ‰æ•ˆæ€§: {evaluation_results.get('validity_score', 'N/A')}")
            logger.info(f"  - å›¾ç»“æ„ç›¸ä¼¼åº¦: {evaluation_results.get('graph_similarity', 'N/A')}")
        else:
            logger.warning("âš ï¸ è´¨é‡è¯„ä¼°è¿”å›ç©ºç»“æœ")
        
        logger.info("ğŸ‰ æ¨ç†ç®¡é“æµ‹è¯•å®Œæˆ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ¨ç†æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        logger.error(traceback.format_exc())
        return False


def test_numerical_stability():
    """
    æµ‹è¯•æ•°å€¼ç¨³å®šæ€§ä¿®å¤
    """
    logger.info("ğŸ”¬ æµ‹è¯•æ•°å€¼ç¨³å®šæ€§ä¿®å¤")
    logger.info("=" * 60)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®ï¼ˆåŒ…å«å¯èƒ½å¯¼è‡´æ•°å€¼é—®é¢˜çš„æƒ…å†µï¼‰
    test_cases = [
        {
            'name': 'é›¶æ ‡å‡†å·®æµ‹è¯•',
            'data1': np.array([1.0, 1.0, 1.0, 1.0, 1.0]),  # å¸¸æ•°å€¼
            'data2': np.array([2.0, 2.0, 2.0, 2.0, 2.0])   # ä¸åŒå¸¸æ•°å€¼
        },
        {
            'name': 'ç›¸åŒå¸¸æ•°æµ‹è¯•',
            'data1': np.array([0.5, 0.5, 0.5, 0.5, 0.5]),  # ç›¸åŒå¸¸æ•°
            'data2': np.array([0.5, 0.5, 0.5, 0.5, 0.5])   # ç›¸åŒå¸¸æ•°
        },
        {
            'name': 'æå°æ–¹å·®æµ‹è¯•',
            'data1': np.array([1.0, 1.0000001, 1.0, 1.0, 1.0]),  # æå°æ–¹å·®
            'data2': np.array([2.0, 2.0, 2.0, 2.0, 2.0])
        },
        {
            'name': 'æ­£å¸¸æ•°æ®æµ‹è¯•',
            'data1': np.array([1.0, 2.0, 3.0, 4.0, 5.0]),  # æ­£å¸¸æ•°æ®
            'data2': np.array([2.0, 4.0, 6.0, 8.0, 10.0])
        }
    ]
    
    success_count = 0
    
    for test_case in test_cases:
        logger.info(f"ğŸ§ª {test_case['name']}")
        
        try:
            # æ¨¡æ‹Ÿinference.pyä¸­çš„æ•°å€¼ç¨³å®šæ€§å¤„ç†
            data1 = test_case['data1']
            data2 = test_case['data2']
            
            # æ£€æŸ¥æ ‡å‡†å·®
            std1 = np.std(data1)
            std2 = np.std(data2)
            
            logger.info(f"  - æ•°æ®1æ ‡å‡†å·®: {std1:.8f}")
            logger.info(f"  - æ•°æ®2æ ‡å‡†å·®: {std2:.8f}")
            
            if std1 < 1e-8 or std2 < 1e-8:
                # æ ‡å‡†å·®ä¸ºé›¶çš„æƒ…å†µ
                mean1 = np.mean(data1)
                mean2 = np.mean(data2)
                
                if abs(mean1 - mean2) < 1e-8:
                    pearson_corr = 1.0  # å®Œå…¨ç›¸åŒçš„å¸¸æ•°å€¼
                    logger.info(f"  - ç»“æœ: ç›¸åŒå¸¸æ•°å€¼ï¼Œç›¸å…³ç³»æ•° = {pearson_corr}")
                else:
                    pearson_corr = 0.0  # ä¸åŒçš„å¸¸æ•°å€¼
                    logger.info(f"  - ç»“æœ: ä¸åŒå¸¸æ•°å€¼ï¼Œç›¸å…³ç³»æ•° = {pearson_corr}")
            else:
                # æ­£å¸¸è®¡ç®—ç›¸å…³ç³»æ•°
                try:
                    corr_matrix = np.corrcoef(data1, data2)
                    pearson_corr = corr_matrix[0, 1]
                    logger.info(f"  - ç»“æœ: æ­£å¸¸è®¡ç®—ï¼Œç›¸å…³ç³»æ•° = {pearson_corr:.6f}")
                except:
                    pearson_corr = 0.0
                    logger.info(f"  - ç»“æœ: è®¡ç®—å¤±è´¥ï¼Œè®¾ä¸º 0.0")
            
            # æ£€æŸ¥ç»“æœæœ‰æ•ˆæ€§
            if np.isfinite(pearson_corr):
                logger.info(f"  âœ… æ•°å€¼ç¨³å®šæ€§æµ‹è¯•é€šè¿‡")
                success_count += 1
            else:
                logger.error(f"  âŒ ç»“æœåŒ…å«æ— æ•ˆå€¼: {pearson_corr}")
                
        except Exception as e:
            logger.error(f"  âŒ æµ‹è¯•å¤±è´¥: {e}")
    
    logger.info(f"ğŸ¯ æ•°å€¼ç¨³å®šæ€§æµ‹è¯•ç»“æœ: {success_count}/{len(test_cases)} é€šè¿‡")
    return success_count == len(test_cases)


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("ğŸš€ å¯åŠ¨Demo 4æ¨ç†åŠŸèƒ½æµ‹è¯•")
    logger.info("=" * 80)
    
    # æ£€æŸ¥ç¯å¢ƒ
    logger.info(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    logger.info(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        logger.info(f"GPUè®¾å¤‡: {torch.cuda.get_device_name()}")
    
    # è®¾ç½®è®¾å¤‡
    device = "cuda" if torch.cuda.is_available() else "cpu"
    logger.info(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    try:
        # 1. æ•°å€¼ç¨³å®šæ€§æµ‹è¯•
        logger.info("\n" + "=" * 50)
        stability_ok = test_numerical_stability()
        
        if not stability_ok:
            logger.error("âŒ æ•°å€¼ç¨³å®šæ€§æµ‹è¯•å¤±è´¥ï¼Œé€€å‡º")
            return False
        
        # 2. æ¨¡å‹è·¯å¾„
        model_path = "/mnt/c/Users/sxk27/OneDrive - MSFT/Project/electrical/output/demo4_g2milp/training/g2milp_training_20250706_220830/final_model.pth"
        
        # 3. æ•°æ®è·¯å¾„
        data_path = "/mnt/c/Users/sxk27/OneDrive - MSFT/Project/electrical/output/demo3_g2milp/bipartite_graphs/demo3_bipartite_graph.pkl"
        
        # 4. åŠ è½½æ¨¡å‹
        logger.info("\n" + "=" * 50)
        model = load_trained_model(model_path, device)
        
        # 5. åŠ è½½æ•°æ®
        logger.info("\n" + "=" * 50)
        source_data = load_demo3_data(data_path)
        source_data = source_data.to(device)
        
        # 6. æ‰§è¡Œæ¨ç†æµ‹è¯•
        logger.info("\n" + "=" * 50)
        inference_ok = test_inference_pipeline(model, source_data)
        
        # 7. è¾“å‡ºæ€»ç»“
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ¯ Demo 4æ¨ç†åŠŸèƒ½æµ‹è¯•æ€»ç»“")
        logger.info("=" * 80)
        
        if stability_ok and inference_ok:
            logger.info("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
            logger.info("ğŸ”§ ä¿®å¤æ•ˆæœ:")
            logger.info("  1. æ•°å€¼ç¨³å®šæ€§é—®é¢˜å·²è§£å†³")
            logger.info("  2. æ¨ç†åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
            logger.info("  3. è´¨é‡è¯„ä¼°ç³»ç»Ÿå®Œå–„")
            logger.info("  4. å¤šæ ·æ€§ç”ŸæˆåŠŸèƒ½æ­£å¸¸")
            return True
        else:
            logger.error("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
            logger.error(f"  - æ•°å€¼ç¨³å®šæ€§: {'âœ…' if stability_ok else 'âŒ'}")
            logger.error(f"  - æ¨ç†åŠŸèƒ½: {'âœ…' if inference_ok else 'âŒ'}")
            return False
            
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        logger.error(traceback.format_exc())
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)